{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Final Project\n",
        "## Author: Jerrin C. Redmon\n",
        "### CS-430\n",
        "### December 12, 2022"
      ],
      "metadata": {
        "id": "KiD-MkF4UwLC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Description\n",
        "##### Link: https://www.kaggle.com/datasets/danushkumarv/glass-identification-data-set\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Hafyj3aOc83q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### About Dataset\n",
        "\n",
        "#### Sources\n",
        "\n",
        "\n",
        "1. Creator: B. German\n",
        "-- Central Research Establishment\n",
        "Home Office Forensic Science Service\n",
        "Aldermaston, Reading, Berkshire RG7 4PN\n",
        "\n",
        "2. Donor: Vina Spiehler, Ph.D., DABFT\n",
        "Diagnostic Products Corporation\n",
        "(213) 776-0180 (ext 3014)\n",
        "\n",
        "3. Date: September 1987\n",
        "Usage\n",
        "\n",
        "    Rule Induction in Forensic Science\n",
        "        Ian W. Evett and Ernest J. Spiehler\n",
        "        Central Research Establishment\n",
        "        Home Office Forensic Science Service\n",
        "        Aldermaston, Reading, Berkshire RG7 4PN\n",
        "        Unknown technical note number (sorry, not listed here)\n",
        "        General Results: nearest neighbor held its own with respect to the\n",
        "        rule-based system\n",
        "\n",
        "Description\n",
        "\n",
        "Vina conducted a comparison test of her rule-based system, BEAGLE, the nearest-neighbor algorithm, and discriminant analysis. BEAGLE is a product available through VRS Consulting, Inc.; 4676 Admiralty Way, Suite 206; Marina Del Ray, CA 90292 (213) 827-7890 and FAX: -3189. The study of the classification of types of glass was motivated by criminological investigation. At the scene of th, the glass left can be used as evidenceâ€¦if it is correctly identified!\n",
        "Number of Instances\n",
        "\n",
        "214\n",
        "Number of Attributes\n",
        "\n",
        "10 (including an Id#) plus the class attribute\n",
        "\n",
        "    all attributes are continuously valued\n",
        "\n",
        "Attribute Information\n",
        "\n",
        "    Id number: 1 to 214\n",
        "    RI: refractive index\n",
        "    Na: Sodium (unit measurement: weight percent in the corresponding oxide, as\n",
        "    are attributes 4-10)\n",
        "    Mg: Magnesium\n",
        "    Al: Aluminum\n",
        "    Si: Silicon\n",
        "    K: Potassium\n",
        "    Ca: Calcium\n",
        "    Ba: Barium\n",
        "        Fe: Iron\n",
        "        Type of glass: (class attribute)\n",
        "            1 buildingwindowsfloat_processed\n",
        "            2 buildingwindowsnonfloatprocessed\n",
        "            3 vehiclewindowsfloat_processed\n",
        "            4 vehiclewindowsnonfloatprocessed (none in this database)\n",
        "            5 containers\n",
        "            6 tableware\n",
        "            7 headlamps\n",
        "\n",
        "Missing Attribute Values:\n",
        "\n",
        "None\n",
        "Class Distribution:\n",
        "\n",
        "(out of 214 total instances)\n",
        "\n",
        "    163 Window glass (building windows and vehicle windows)\n",
        "        87 float processed\n",
        "            70 building windows\n",
        "            17 vehicle windows\n",
        "        76 non-float processed\n",
        "            76 building windows\n",
        "            0 vehicle windows\n",
        "    51 Non-window glass\n",
        "        13 containers\n",
        "        9 tableware\n",
        "        29 headlamps\n"
      ],
      "metadata": {
        "id": "wmHR3v2LdGYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Begining of data analysis\n"
      ],
      "metadata": {
        "id": "0Gs8Sj1GdaeC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imported Libraries"
      ],
      "metadata": {
        "id": "4iPfaNZQU65t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "QFAq8RAhU5nA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing dataset"
      ],
      "metadata": {
        "id": "pAuCI0xGVcmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glass = pd.read_csv('/content/glass.csv')"
      ],
      "metadata": {
        "id": "Qs1mKP-cVP2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glass.head()"
      ],
      "metadata": {
        "id": "oKm-_iy_VkyT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c2a5d9e8-57f0-48c4-c9d7-acac0be68679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id       RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type of glass\n",
              "0   1  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0              1\n",
              "1   2  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0              1\n",
              "2   3  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0              1\n",
              "3   4  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0              1\n",
              "4   5  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1758a020-86c1-49c8-ae83-12359ab4ec7a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>RI</th>\n",
              "      <th>Na</th>\n",
              "      <th>Mg</th>\n",
              "      <th>Al</th>\n",
              "      <th>Si</th>\n",
              "      <th>K</th>\n",
              "      <th>Ca</th>\n",
              "      <th>Ba</th>\n",
              "      <th>Fe</th>\n",
              "      <th>Type of glass</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1.52101</td>\n",
              "      <td>13.64</td>\n",
              "      <td>4.49</td>\n",
              "      <td>1.10</td>\n",
              "      <td>71.78</td>\n",
              "      <td>0.06</td>\n",
              "      <td>8.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1.51761</td>\n",
              "      <td>13.89</td>\n",
              "      <td>3.60</td>\n",
              "      <td>1.36</td>\n",
              "      <td>72.73</td>\n",
              "      <td>0.48</td>\n",
              "      <td>7.83</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.51618</td>\n",
              "      <td>13.53</td>\n",
              "      <td>3.55</td>\n",
              "      <td>1.54</td>\n",
              "      <td>72.99</td>\n",
              "      <td>0.39</td>\n",
              "      <td>7.78</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1.51766</td>\n",
              "      <td>13.21</td>\n",
              "      <td>3.69</td>\n",
              "      <td>1.29</td>\n",
              "      <td>72.61</td>\n",
              "      <td>0.57</td>\n",
              "      <td>8.22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1.51742</td>\n",
              "      <td>13.27</td>\n",
              "      <td>3.62</td>\n",
              "      <td>1.24</td>\n",
              "      <td>73.08</td>\n",
              "      <td>0.55</td>\n",
              "      <td>8.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1758a020-86c1-49c8-ae83-12359ab4ec7a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1758a020-86c1-49c8-ae83-12359ab4ec7a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1758a020-86c1-49c8-ae83-12359ab4ec7a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glass.describe()"
      ],
      "metadata": {
        "id": "7_W31-nHVpLZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "c2a6809e-7fda-4add-c1f4-3ddf80549367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Id          RI          Na          Mg          Al          Si  \\\n",
              "count  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000   \n",
              "mean   107.500000    1.518365   13.407850    2.684533    1.444907   72.650935   \n",
              "std     61.920648    0.003037    0.816604    1.442408    0.499270    0.774546   \n",
              "min      1.000000    1.511150   10.730000    0.000000    0.290000   69.810000   \n",
              "25%     54.250000    1.516522   12.907500    2.115000    1.190000   72.280000   \n",
              "50%    107.500000    1.517680   13.300000    3.480000    1.360000   72.790000   \n",
              "75%    160.750000    1.519157   13.825000    3.600000    1.630000   73.087500   \n",
              "max    214.000000    1.533930   17.380000    4.490000    3.500000   75.410000   \n",
              "\n",
              "                K          Ca          Ba          Fe  Type of glass  \n",
              "count  214.000000  214.000000  214.000000  214.000000     214.000000  \n",
              "mean     0.497056    8.956963    0.175047    0.057009       2.780374  \n",
              "std      0.652192    1.423153    0.497219    0.097439       2.103739  \n",
              "min      0.000000    5.430000    0.000000    0.000000       1.000000  \n",
              "25%      0.122500    8.240000    0.000000    0.000000       1.000000  \n",
              "50%      0.555000    8.600000    0.000000    0.000000       2.000000  \n",
              "75%      0.610000    9.172500    0.000000    0.100000       3.000000  \n",
              "max      6.210000   16.190000    3.150000    0.510000       7.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0c1ba2f-b8d2-45c2-b811-ec026d60ec99\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>RI</th>\n",
              "      <th>Na</th>\n",
              "      <th>Mg</th>\n",
              "      <th>Al</th>\n",
              "      <th>Si</th>\n",
              "      <th>K</th>\n",
              "      <th>Ca</th>\n",
              "      <th>Ba</th>\n",
              "      <th>Fe</th>\n",
              "      <th>Type of glass</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>214.000000</td>\n",
              "      <td>214.000000</td>\n",
              "      <td>214.000000</td>\n",
              "      <td>214.000000</td>\n",
              "      <td>214.000000</td>\n",
              "      <td>214.000000</td>\n",
              "      <td>214.000000</td>\n",
              "      <td>214.000000</td>\n",
              "      <td>214.000000</td>\n",
              "      <td>214.000000</td>\n",
              "      <td>214.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>107.500000</td>\n",
              "      <td>1.518365</td>\n",
              "      <td>13.407850</td>\n",
              "      <td>2.684533</td>\n",
              "      <td>1.444907</td>\n",
              "      <td>72.650935</td>\n",
              "      <td>0.497056</td>\n",
              "      <td>8.956963</td>\n",
              "      <td>0.175047</td>\n",
              "      <td>0.057009</td>\n",
              "      <td>2.780374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>61.920648</td>\n",
              "      <td>0.003037</td>\n",
              "      <td>0.816604</td>\n",
              "      <td>1.442408</td>\n",
              "      <td>0.499270</td>\n",
              "      <td>0.774546</td>\n",
              "      <td>0.652192</td>\n",
              "      <td>1.423153</td>\n",
              "      <td>0.497219</td>\n",
              "      <td>0.097439</td>\n",
              "      <td>2.103739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.511150</td>\n",
              "      <td>10.730000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>69.810000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.430000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>54.250000</td>\n",
              "      <td>1.516522</td>\n",
              "      <td>12.907500</td>\n",
              "      <td>2.115000</td>\n",
              "      <td>1.190000</td>\n",
              "      <td>72.280000</td>\n",
              "      <td>0.122500</td>\n",
              "      <td>8.240000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>107.500000</td>\n",
              "      <td>1.517680</td>\n",
              "      <td>13.300000</td>\n",
              "      <td>3.480000</td>\n",
              "      <td>1.360000</td>\n",
              "      <td>72.790000</td>\n",
              "      <td>0.555000</td>\n",
              "      <td>8.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>160.750000</td>\n",
              "      <td>1.519157</td>\n",
              "      <td>13.825000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>1.630000</td>\n",
              "      <td>73.087500</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>9.172500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>214.000000</td>\n",
              "      <td>1.533930</td>\n",
              "      <td>17.380000</td>\n",
              "      <td>4.490000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>75.410000</td>\n",
              "      <td>6.210000</td>\n",
              "      <td>16.190000</td>\n",
              "      <td>3.150000</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0c1ba2f-b8d2-45c2-b811-ec026d60ec99')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c0c1ba2f-b8d2-45c2-b811-ec026d60ec99 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c0c1ba2f-b8d2-45c2-b811-ec026d60ec99');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glass.info()"
      ],
      "metadata": {
        "id": "tBvmkpJaVrbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdbd0f97-2587-49a3-bcad-b6ccf2552cc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 214 entries, 0 to 213\n",
            "Data columns (total 11 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Id             214 non-null    int64  \n",
            " 1   RI             214 non-null    float64\n",
            " 2   Na             214 non-null    float64\n",
            " 3   Mg             214 non-null    float64\n",
            " 4   Al             214 non-null    float64\n",
            " 5   Si             214 non-null    float64\n",
            " 6   K              214 non-null    float64\n",
            " 7   Ca             214 non-null    float64\n",
            " 8   Ba             214 non-null    float64\n",
            " 9   Fe             214 non-null    float64\n",
            " 10  Type of glass  214 non-null    int64  \n",
            "dtypes: float64(9), int64(2)\n",
            "memory usage: 18.5 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cleaning Data"
      ],
      "metadata": {
        "id": "wLLrbIlUgvaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping unneeded columns\n",
        "glass = glass.drop('Id', axis = 1)"
      ],
      "metadata": {
        "id": "UvOXpBvmV06B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glass.columns"
      ],
      "metadata": {
        "id": "iCSTPhbOftZr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "648457dd-ddf9-4d97-8b27-7854b345ac43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'Type of glass'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glass.columns = ['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'Type']"
      ],
      "metadata": {
        "id": "1zGhTJvkf2nK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glass.head()"
      ],
      "metadata": {
        "id": "trcYOMqkgOPI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "17af42b2-f731-420c-9c47-f22142398580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
              "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
              "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
              "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
              "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
              "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-afcf9acf-20df-4814-96b1-ce8d334c7d85\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RI</th>\n",
              "      <th>Na</th>\n",
              "      <th>Mg</th>\n",
              "      <th>Al</th>\n",
              "      <th>Si</th>\n",
              "      <th>K</th>\n",
              "      <th>Ca</th>\n",
              "      <th>Ba</th>\n",
              "      <th>Fe</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.52101</td>\n",
              "      <td>13.64</td>\n",
              "      <td>4.49</td>\n",
              "      <td>1.10</td>\n",
              "      <td>71.78</td>\n",
              "      <td>0.06</td>\n",
              "      <td>8.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.51761</td>\n",
              "      <td>13.89</td>\n",
              "      <td>3.60</td>\n",
              "      <td>1.36</td>\n",
              "      <td>72.73</td>\n",
              "      <td>0.48</td>\n",
              "      <td>7.83</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.51618</td>\n",
              "      <td>13.53</td>\n",
              "      <td>3.55</td>\n",
              "      <td>1.54</td>\n",
              "      <td>72.99</td>\n",
              "      <td>0.39</td>\n",
              "      <td>7.78</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.51766</td>\n",
              "      <td>13.21</td>\n",
              "      <td>3.69</td>\n",
              "      <td>1.29</td>\n",
              "      <td>72.61</td>\n",
              "      <td>0.57</td>\n",
              "      <td>8.22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.51742</td>\n",
              "      <td>13.27</td>\n",
              "      <td>3.62</td>\n",
              "      <td>1.24</td>\n",
              "      <td>73.08</td>\n",
              "      <td>0.55</td>\n",
              "      <td>8.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afcf9acf-20df-4814-96b1-ce8d334c7d85')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-afcf9acf-20df-4814-96b1-ce8d334c7d85 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-afcf9acf-20df-4814-96b1-ce8d334c7d85');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glass.info()"
      ],
      "metadata": {
        "id": "pNkmrl_jhQMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2cd3a60-ca13-4a5e-f835-f5073872e04d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 214 entries, 0 to 213\n",
            "Data columns (total 10 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   RI      214 non-null    float64\n",
            " 1   Na      214 non-null    float64\n",
            " 2   Mg      214 non-null    float64\n",
            " 3   Al      214 non-null    float64\n",
            " 4   Si      214 non-null    float64\n",
            " 5   K       214 non-null    float64\n",
            " 6   Ca      214 non-null    float64\n",
            " 7   Ba      214 non-null    float64\n",
            " 8   Fe      214 non-null    float64\n",
            " 9   Type    214 non-null    int64  \n",
            "dtypes: float64(9), int64(1)\n",
            "memory usage: 16.8 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(glass['Type'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "qeJtvhe4qEAl",
        "outputId": "29cb0c48-7bfd-4eab-cea1-371e34a58097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([70., 76.,  0., 17.,  0.,  0., 13.,  0.,  9., 29.]),\n",
              " array([1. , 1.6, 2.2, 2.8, 3.4, 4. , 4.6, 5.2, 5.8, 6.4, 7. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data split and preparation"
      ],
      "metadata": {
        "id": "_f8SwCDDhElg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting data, setting the target as the type of glass\n",
        "X = glass.drop('Type', axis = 1)\n",
        "y = glass['Type']"
      ],
      "metadata": {
        "id": "HJUE0fayhyFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "#Help with the imbalance in the dataset\n",
        "oversample = SMOTE()\n",
        "X, y = oversample.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "SHAXugELrSfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import train test split\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "nWq8swYdgPTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = .2, random_state = 42, stratify = y)"
      ],
      "metadata": {
        "id": "gyZxCbdihuxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1: Logistic Regression"
      ],
      "metadata": {
        "id": "VGf0J4_flM76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_regressor = LogisticRegression(max_iter = 5000)\n",
        "logistic_regressor.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "kspd4vMeiytK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeabe56a-1c0e-4cb7-df17-7e5c6e41c398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=5000)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test score\n",
        "logistic_regressor.score(X_test,y_test)"
      ],
      "metadata": {
        "id": "HwfHUbfDlYbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35add953-beb5-4546-a308-70ee1ec4e9c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7065217391304348"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train score\n",
        "logistic_regressor.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "6GIw0xs9lh63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b155632c-c97b-4ce5-dba7-fb5507172878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2: RandomForestClassifier"
      ],
      "metadata": {
        "id": "-w_fTGspnUAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "RFC = RandomForestClassifier()\n",
        "RFC.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "nKDjMa43mvIr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d25ec7db-a94e-4d75-9936-946df3dd7526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test score\n",
        "RFC.score(X_test,y_test)"
      ],
      "metadata": {
        "id": "uVcvRUDonbxd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3f18362-681e-43b6-9867-e20f4737709e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8695652173913043"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train score\n",
        "RFC.score(X_train,y_train)"
      ],
      "metadata": {
        "id": "IfCcGkMZnw1O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "815dc92e-1967-446f-ad05-c43c02a2cd81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3: Support Vector Classifier (SVC)"
      ],
      "metadata": {
        "id": "NHMJ0kKsoElW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "svc = SVC()\n",
        "svc.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "A93JzR4xn_zJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "720be99b-51fd-4e87-d830-81c7188b6fa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test score\n",
        "svc.score(X_test,y_test)"
      ],
      "metadata": {
        "id": "XLuzrkazopsQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30f5a06f-e6db-4b8d-b8e0-2e9bce578ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3695652173913043"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train score\n",
        "svc.score(X_train,y_train)"
      ],
      "metadata": {
        "id": "cBicbKd7ovLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "678e32aa-cf2d-470b-a415-36baf33882c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3983516483516483"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4: Decision Tree Classifier"
      ],
      "metadata": {
        "id": "L3Z0wIF5o5-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "DTC = DecisionTreeClassifier()\n",
        "DTC.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "EFBLdLEuoyk-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0439af32-e9e8-47da-b161-3993b8a07554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test score\n",
        "DTC.score(X_test,y_test)"
      ],
      "metadata": {
        "id": "wdeIF7KLpIRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f9b3ec3-eb81-4358-c275-860a255e1547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8586956521739131"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train score\n",
        "DTC.score(X_train,y_train)"
      ],
      "metadata": {
        "id": "YDLX7jF-pL11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2c29241-3642-46c8-8b06-49a951d1ae4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameter Tuning"
      ],
      "metadata": {
        "id": "dHF50ISjpWQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model parameters"
      ],
      "metadata": {
        "id": "28tFY1pkpsOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_params = {'SVC':{'model':SVC(gamma = 'auto'),\n",
        "                       'params':{ 'C':[.1,1,10,20,100],\n",
        "                                 'kernel':['rbf','linear','poly'],\n",
        "                                 \n",
        "     }\n",
        "  },\n",
        "  \n",
        "  'Logistic_Regession':{\n",
        "      'model':LogisticRegression(),\n",
        "      'params':{\n",
        "          'penalty':['l1','l2','elasticnet','none'],\n",
        "          'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']          \n",
        "      }\n",
        "  },\n",
        "  'Random_Forest':{\n",
        "      'model':RandomForestClassifier(),\n",
        "      'params':{\n",
        "          'criterion':['gini','entropy','log_loss'],\n",
        "          'max_depth':[2,3,4,5]\n",
        "      }\n",
        "  },\n",
        "  'Decision_Tree':{\n",
        "      'model':DecisionTreeClassifier(),\n",
        "      'params':{\n",
        "          'criterion':['gini','entropy'],\n",
        "          'max_depth':[2,3,4,5]\n",
        "      }\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "id": "4LESKHT3pu02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### parameter tuning using Grid Search CV"
      ],
      "metadata": {
        "id": "M0-B8f9UpcsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "best_params = []\n",
        "\n",
        "for model in model_params:\n",
        "  grid_model = GridSearchCV(model_params[model]['model'],model_params[model]['params'], verbose = 3, cv = 5)\n",
        "  grid_model.fit(X_train,y_train)\n",
        "  best_params.append({\n",
        "    'model':model,\n",
        "    'best_score':grid_model.best_score_,\n",
        "    'best_params':grid_model.best_params_\n",
        "  })\n",
        "\n"
      ],
      "metadata": {
        "id": "A3Qy3yrOpSZI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6dcb8fc-eb41-4302-c4f9-3e05b6816b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
            "[CV 1/5] END .................C=0.1, kernel=rbf;, score=0.712 total time=   0.0s\n",
            "[CV 2/5] END .................C=0.1, kernel=rbf;, score=0.644 total time=   0.0s\n",
            "[CV 3/5] END .................C=0.1, kernel=rbf;, score=0.699 total time=   0.0s\n",
            "[CV 4/5] END .................C=0.1, kernel=rbf;, score=0.616 total time=   0.0s\n",
            "[CV 5/5] END .................C=0.1, kernel=rbf;, score=0.667 total time=   0.0s\n",
            "[CV 1/5] END ..............C=0.1, kernel=linear;, score=0.767 total time=   0.0s\n",
            "[CV 2/5] END ..............C=0.1, kernel=linear;, score=0.589 total time=   0.0s\n",
            "[CV 3/5] END ..............C=0.1, kernel=linear;, score=0.712 total time=   0.0s\n",
            "[CV 4/5] END ..............C=0.1, kernel=linear;, score=0.726 total time=   0.0s\n",
            "[CV 5/5] END ..............C=0.1, kernel=linear;, score=0.681 total time=   0.0s\n",
            "[CV 1/5] END ................C=0.1, kernel=poly;, score=0.890 total time=   0.2s\n",
            "[CV 2/5] END ................C=0.1, kernel=poly;, score=0.808 total time=   0.2s\n",
            "[CV 3/5] END ................C=0.1, kernel=poly;, score=0.836 total time=   0.2s\n",
            "[CV 4/5] END ................C=0.1, kernel=poly;, score=0.836 total time=   0.2s\n",
            "[CV 5/5] END ................C=0.1, kernel=poly;, score=0.819 total time=   0.2s\n",
            "[CV 1/5] END ...................C=1, kernel=rbf;, score=0.836 total time=   0.0s\n",
            "[CV 2/5] END ...................C=1, kernel=rbf;, score=0.726 total time=   0.0s\n",
            "[CV 3/5] END ...................C=1, kernel=rbf;, score=0.781 total time=   0.0s\n",
            "[CV 4/5] END ...................C=1, kernel=rbf;, score=0.822 total time=   0.0s\n",
            "[CV 5/5] END ...................C=1, kernel=rbf;, score=0.750 total time=   0.0s\n",
            "[CV 1/5] END ................C=1, kernel=linear;, score=0.808 total time=   0.0s\n",
            "[CV 2/5] END ................C=1, kernel=linear;, score=0.753 total time=   0.0s\n",
            "[CV 3/5] END ................C=1, kernel=linear;, score=0.767 total time=   0.0s\n",
            "[CV 4/5] END ................C=1, kernel=linear;, score=0.822 total time=   0.0s\n",
            "[CV 5/5] END ................C=1, kernel=linear;, score=0.736 total time=   0.0s\n",
            "[CV 1/5] END ..................C=1, kernel=poly;, score=0.877 total time=   0.2s\n",
            "[CV 2/5] END ..................C=1, kernel=poly;, score=0.822 total time=   0.2s\n",
            "[CV 3/5] END ..................C=1, kernel=poly;, score=0.795 total time=   0.5s\n",
            "[CV 4/5] END ..................C=1, kernel=poly;, score=0.795 total time=   0.2s\n",
            "[CV 5/5] END ..................C=1, kernel=poly;, score=0.764 total time=   0.3s\n",
            "[CV 1/5] END ..................C=10, kernel=rbf;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END ..................C=10, kernel=rbf;, score=0.781 total time=   0.0s\n",
            "[CV 3/5] END ..................C=10, kernel=rbf;, score=0.849 total time=   0.0s\n",
            "[CV 4/5] END ..................C=10, kernel=rbf;, score=0.808 total time=   0.0s\n",
            "[CV 5/5] END ..................C=10, kernel=rbf;, score=0.806 total time=   0.0s\n",
            "[CV 1/5] END ...............C=10, kernel=linear;, score=0.822 total time=   0.0s\n",
            "[CV 2/5] END ...............C=10, kernel=linear;, score=0.740 total time=   0.0s\n",
            "[CV 3/5] END ...............C=10, kernel=linear;, score=0.808 total time=   0.0s\n",
            "[CV 4/5] END ...............C=10, kernel=linear;, score=0.822 total time=   0.0s\n",
            "[CV 5/5] END ...............C=10, kernel=linear;, score=0.736 total time=   0.0s\n",
            "[CV 1/5] END .................C=10, kernel=poly;, score=0.890 total time=   0.5s\n",
            "[CV 2/5] END .................C=10, kernel=poly;, score=0.822 total time=   0.3s\n",
            "[CV 3/5] END .................C=10, kernel=poly;, score=0.767 total time=   0.8s\n",
            "[CV 4/5] END .................C=10, kernel=poly;, score=0.808 total time=   0.5s\n",
            "[CV 5/5] END .................C=10, kernel=poly;, score=0.792 total time=   0.5s\n",
            "[CV 1/5] END ..................C=20, kernel=rbf;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END ..................C=20, kernel=rbf;, score=0.795 total time=   0.0s\n",
            "[CV 3/5] END ..................C=20, kernel=rbf;, score=0.863 total time=   0.0s\n",
            "[CV 4/5] END ..................C=20, kernel=rbf;, score=0.808 total time=   0.0s\n",
            "[CV 5/5] END ..................C=20, kernel=rbf;, score=0.833 total time=   0.0s\n",
            "[CV 1/5] END ...............C=20, kernel=linear;, score=0.836 total time=   0.0s\n",
            "[CV 2/5] END ...............C=20, kernel=linear;, score=0.712 total time=   0.0s\n",
            "[CV 3/5] END ...............C=20, kernel=linear;, score=0.795 total time=   0.0s\n",
            "[CV 4/5] END ...............C=20, kernel=linear;, score=0.822 total time=   0.0s\n",
            "[CV 5/5] END ...............C=20, kernel=linear;, score=0.750 total time=   0.0s\n",
            "[CV 1/5] END .................C=20, kernel=poly;, score=0.863 total time=   0.4s\n",
            "[CV 2/5] END .................C=20, kernel=poly;, score=0.836 total time=   0.2s\n",
            "[CV 3/5] END .................C=20, kernel=poly;, score=0.795 total time=   0.6s\n",
            "[CV 4/5] END .................C=20, kernel=poly;, score=0.808 total time=   0.5s\n",
            "[CV 5/5] END .................C=20, kernel=poly;, score=0.806 total time=   0.5s\n",
            "[CV 1/5] END .................C=100, kernel=rbf;, score=0.890 total time=   0.0s\n",
            "[CV 2/5] END .................C=100, kernel=rbf;, score=0.863 total time=   0.0s\n",
            "[CV 3/5] END .................C=100, kernel=rbf;, score=0.863 total time=   0.0s\n",
            "[CV 4/5] END .................C=100, kernel=rbf;, score=0.781 total time=   0.0s\n",
            "[CV 5/5] END .................C=100, kernel=rbf;, score=0.806 total time=   0.0s\n",
            "[CV 1/5] END ..............C=100, kernel=linear;, score=0.849 total time=   0.0s\n",
            "[CV 2/5] END ..............C=100, kernel=linear;, score=0.740 total time=   0.0s\n",
            "[CV 3/5] END ..............C=100, kernel=linear;, score=0.808 total time=   0.0s\n",
            "[CV 4/5] END ..............C=100, kernel=linear;, score=0.795 total time=   0.0s\n",
            "[CV 5/5] END ..............C=100, kernel=linear;, score=0.792 total time=   0.0s\n",
            "[CV 1/5] END ................C=100, kernel=poly;, score=0.863 total time=   0.6s\n",
            "[CV 2/5] END ................C=100, kernel=poly;, score=0.795 total time=   0.2s\n",
            "[CV 3/5] END ................C=100, kernel=poly;, score=0.767 total time=   0.8s\n",
            "[CV 4/5] END ................C=100, kernel=poly;, score=0.808 total time=   0.4s\n",
            "[CV 5/5] END ................C=100, kernel=poly;, score=0.778 total time=   0.7s\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "[CV 1/5] END ........penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END ........penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END ........penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END ........penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END ........penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END ............penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END ............penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END ............penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END ............penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END ............penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END ......penalty=l1, solver=liblinear;, score=0.767 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END ......penalty=l1, solver=liblinear;, score=0.658 total time=   0.1s\n",
            "[CV 3/5] END ......penalty=l1, solver=liblinear;, score=0.712 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END ......penalty=l1, solver=liblinear;, score=0.740 total time=   0.1s\n",
            "[CV 5/5] END ......penalty=l1, solver=liblinear;, score=0.653 total time=   0.1s\n",
            "[CV 1/5] END ..............penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END ..............penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END ..............penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END ..............penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END ..............penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END ...........penalty=l1, solver=saga;, score=0.685 total time=   0.0s\n",
            "[CV 2/5] END ...........penalty=l1, solver=saga;, score=0.575 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END ...........penalty=l1, solver=saga;, score=0.740 total time=   0.0s\n",
            "[CV 4/5] END ...........penalty=l1, solver=saga;, score=0.603 total time=   0.0s\n",
            "[CV 5/5] END ...........penalty=l1, solver=saga;, score=0.681 total time=   0.0s\n",
            "[CV 1/5] END ......penalty=l2, solver=newton-cg;, score=0.753 total time=   0.2s\n",
            "[CV 2/5] END ......penalty=l2, solver=newton-cg;, score=0.699 total time=   0.2s\n",
            "[CV 3/5] END ......penalty=l2, solver=newton-cg;, score=0.699 total time=   0.2s\n",
            "[CV 4/5] END ......penalty=l2, solver=newton-cg;, score=0.740 total time=   0.2s\n",
            "[CV 5/5] END ......penalty=l2, solver=newton-cg;, score=0.694 total time=   0.2s\n",
            "[CV 1/5] END ..........penalty=l2, solver=lbfgs;, score=0.740 total time=   0.1s\n",
            "[CV 2/5] END ..........penalty=l2, solver=lbfgs;, score=0.699 total time=   0.0s\n",
            "[CV 3/5] END ..........penalty=l2, solver=lbfgs;, score=0.740 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END ..........penalty=l2, solver=lbfgs;, score=0.753 total time=   0.1s\n",
            "[CV 5/5] END ..........penalty=l2, solver=lbfgs;, score=0.694 total time=   0.1s\n",
            "[CV 1/5] END ......penalty=l2, solver=liblinear;, score=0.740 total time=   0.0s\n",
            "[CV 2/5] END ......penalty=l2, solver=liblinear;, score=0.658 total time=   0.0s\n",
            "[CV 3/5] END ......penalty=l2, solver=liblinear;, score=0.699 total time=   0.0s\n",
            "[CV 4/5] END ......penalty=l2, solver=liblinear;, score=0.740 total time=   0.0s\n",
            "[CV 5/5] END ......penalty=l2, solver=liblinear;, score=0.667 total time=   0.0s\n",
            "[CV 1/5] END ............penalty=l2, solver=sag;, score=0.699 total time=   0.0s\n",
            "[CV 2/5] END ............penalty=l2, solver=sag;, score=0.603 total time=   0.0s\n",
            "[CV 3/5] END ............penalty=l2, solver=sag;, score=0.740 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END ............penalty=l2, solver=sag;, score=0.644 total time=   0.0s\n",
            "[CV 5/5] END ............penalty=l2, solver=sag;, score=0.681 total time=   0.0s\n",
            "[CV 1/5] END ...........penalty=l2, solver=saga;, score=0.712 total time=   0.0s\n",
            "[CV 2/5] END ...........penalty=l2, solver=saga;, score=0.575 total time=   0.0s\n",
            "[CV 3/5] END ...........penalty=l2, solver=saga;, score=0.740 total time=   0.0s\n",
            "[CV 4/5] END ...........penalty=l2, solver=saga;, score=0.603 total time=   0.0s\n",
            "[CV 5/5] END ...........penalty=l2, solver=saga;, score=0.653 total time=   0.0s\n",
            "[CV 1/5] END penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END ....penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END ....penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END ....penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END ....penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END ....penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 2/5] END penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 3/5] END penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 4/5] END penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 5/5] END penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 1/5] END ......penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END ......penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END ......penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END ......penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END ......penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END .....penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
            "[CV 2/5] END .....penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
            "[CV 3/5] END .....penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
            "[CV 4/5] END .....penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
            "[CV 5/5] END .....penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END ....penalty=none, solver=newton-cg;, score=0.863 total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END ....penalty=none, solver=newton-cg;, score=0.795 total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END ....penalty=none, solver=newton-cg;, score=0.795 total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END ....penalty=none, solver=newton-cg;, score=0.781 total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END ....penalty=none, solver=newton-cg;, score=0.833 total time=   0.5s\n",
            "[CV 1/5] END ........penalty=none, solver=lbfgs;, score=0.767 total time=   0.0s\n",
            "[CV 2/5] END ........penalty=none, solver=lbfgs;, score=0.740 total time=   0.0s\n",
            "[CV 3/5] END ........penalty=none, solver=lbfgs;, score=0.781 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END ........penalty=none, solver=lbfgs;, score=0.767 total time=   0.1s\n",
            "[CV 5/5] END ........penalty=none, solver=lbfgs;, score=0.708 total time=   0.0s\n",
            "[CV 1/5] END ......penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 2/5] END ......penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 3/5] END ......penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 4/5] END ......penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 5/5] END ......penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
            "[CV 1/5] END ..........penalty=none, solver=sag;, score=0.699 total time=   0.0s\n",
            "[CV 2/5] END ..........penalty=none, solver=sag;, score=0.603 total time=   0.0s\n",
            "[CV 3/5] END ..........penalty=none, solver=sag;, score=0.740 total time=   0.0s\n",
            "[CV 4/5] END ..........penalty=none, solver=sag;, score=0.644 total time=   0.0s\n",
            "[CV 5/5] END ..........penalty=none, solver=sag;, score=0.681 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "45 fits failed out of a total of 100.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
            "    raise ValueError(\n",
            "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
            "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
            "ValueError: penalty='none' is not supported for the liblinear solver\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70589802        nan 0.65665906 0.71697108\n",
            " 0.72519026 0.70045662 0.67309741 0.65658295        nan        nan\n",
            "        nan        nan        nan 0.81324201 0.75262557        nan\n",
            " 0.67309741 0.65658295]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END .........penalty=none, solver=saga;, score=0.712 total time=   0.0s\n",
            "[CV 2/5] END .........penalty=none, solver=saga;, score=0.575 total time=   0.0s\n",
            "[CV 3/5] END .........penalty=none, solver=saga;, score=0.740 total time=   0.0s\n",
            "[CV 4/5] END .........penalty=none, solver=saga;, score=0.603 total time=   0.0s\n",
            "[CV 5/5] END .........penalty=none, solver=saga;, score=0.653 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "[CV 1/5] END .......criterion=gini, max_depth=2;, score=0.808 total time=   0.2s\n",
            "[CV 2/5] END .......criterion=gini, max_depth=2;, score=0.726 total time=   0.2s\n",
            "[CV 3/5] END .......criterion=gini, max_depth=2;, score=0.795 total time=   0.2s\n",
            "[CV 4/5] END .......criterion=gini, max_depth=2;, score=0.767 total time=   0.2s\n",
            "[CV 5/5] END .......criterion=gini, max_depth=2;, score=0.750 total time=   0.2s\n",
            "[CV 1/5] END .......criterion=gini, max_depth=3;, score=0.849 total time=   0.2s\n",
            "[CV 2/5] END .......criterion=gini, max_depth=3;, score=0.753 total time=   0.2s\n",
            "[CV 3/5] END .......criterion=gini, max_depth=3;, score=0.808 total time=   0.2s\n",
            "[CV 4/5] END .......criterion=gini, max_depth=3;, score=0.808 total time=   0.2s\n",
            "[CV 5/5] END .......criterion=gini, max_depth=3;, score=0.778 total time=   0.2s\n",
            "[CV 1/5] END .......criterion=gini, max_depth=4;, score=0.863 total time=   0.2s\n",
            "[CV 2/5] END .......criterion=gini, max_depth=4;, score=0.753 total time=   0.2s\n",
            "[CV 3/5] END .......criterion=gini, max_depth=4;, score=0.822 total time=   0.2s\n",
            "[CV 4/5] END .......criterion=gini, max_depth=4;, score=0.863 total time=   0.2s\n",
            "[CV 5/5] END .......criterion=gini, max_depth=4;, score=0.806 total time=   0.2s\n",
            "[CV 1/5] END .......criterion=gini, max_depth=5;, score=0.890 total time=   0.2s\n",
            "[CV 2/5] END .......criterion=gini, max_depth=5;, score=0.863 total time=   0.2s\n",
            "[CV 3/5] END .......criterion=gini, max_depth=5;, score=0.863 total time=   0.2s\n",
            "[CV 4/5] END .......criterion=gini, max_depth=5;, score=0.863 total time=   0.2s\n",
            "[CV 5/5] END .......criterion=gini, max_depth=5;, score=0.833 total time=   0.2s\n",
            "[CV 1/5] END ....criterion=entropy, max_depth=2;, score=0.822 total time=   0.2s\n",
            "[CV 2/5] END ....criterion=entropy, max_depth=2;, score=0.712 total time=   0.2s\n",
            "[CV 3/5] END ....criterion=entropy, max_depth=2;, score=0.822 total time=   0.2s\n",
            "[CV 4/5] END ....criterion=entropy, max_depth=2;, score=0.795 total time=   0.2s\n",
            "[CV 5/5] END ....criterion=entropy, max_depth=2;, score=0.750 total time=   0.2s\n",
            "[CV 1/5] END ....criterion=entropy, max_depth=3;, score=0.836 total time=   0.2s\n",
            "[CV 2/5] END ....criterion=entropy, max_depth=3;, score=0.712 total time=   0.2s\n",
            "[CV 3/5] END ....criterion=entropy, max_depth=3;, score=0.849 total time=   0.2s\n",
            "[CV 4/5] END ....criterion=entropy, max_depth=3;, score=0.822 total time=   0.2s\n",
            "[CV 5/5] END ....criterion=entropy, max_depth=3;, score=0.750 total time=   0.2s\n",
            "[CV 1/5] END ....criterion=entropy, max_depth=4;, score=0.863 total time=   0.2s\n",
            "[CV 2/5] END ....criterion=entropy, max_depth=4;, score=0.781 total time=   0.2s\n",
            "[CV 3/5] END ....criterion=entropy, max_depth=4;, score=0.822 total time=   0.2s\n",
            "[CV 4/5] END ....criterion=entropy, max_depth=4;, score=0.877 total time=   0.2s\n",
            "[CV 5/5] END ....criterion=entropy, max_depth=4;, score=0.792 total time=   0.2s\n",
            "[CV 1/5] END ....criterion=entropy, max_depth=5;, score=0.904 total time=   0.2s\n",
            "[CV 2/5] END ....criterion=entropy, max_depth=5;, score=0.877 total time=   0.3s\n",
            "[CV 3/5] END ....criterion=entropy, max_depth=5;, score=0.890 total time=   0.8s\n",
            "[CV 4/5] END ....criterion=entropy, max_depth=5;, score=0.849 total time=   0.4s\n",
            "[CV 5/5] END ....criterion=entropy, max_depth=5;, score=0.819 total time=   0.5s\n",
            "[CV 1/5] END .....criterion=log_loss, max_depth=2;, score=nan total time=   0.1s\n",
            "[CV 2/5] END .....criterion=log_loss, max_depth=2;, score=nan total time=   0.1s\n",
            "[CV 3/5] END .....criterion=log_loss, max_depth=2;, score=nan total time=   0.1s\n",
            "[CV 4/5] END .....criterion=log_loss, max_depth=2;, score=nan total time=   0.1s\n",
            "[CV 5/5] END .....criterion=log_loss, max_depth=2;, score=nan total time=   0.1s\n",
            "[CV 1/5] END .....criterion=log_loss, max_depth=3;, score=nan total time=   0.1s\n",
            "[CV 2/5] END .....criterion=log_loss, max_depth=3;, score=nan total time=   0.1s\n",
            "[CV 3/5] END .....criterion=log_loss, max_depth=3;, score=nan total time=   0.1s\n",
            "[CV 4/5] END .....criterion=log_loss, max_depth=3;, score=nan total time=   0.1s\n",
            "[CV 5/5] END .....criterion=log_loss, max_depth=3;, score=nan total time=   0.0s\n",
            "[CV 1/5] END .....criterion=log_loss, max_depth=4;, score=nan total time=   0.0s\n",
            "[CV 2/5] END .....criterion=log_loss, max_depth=4;, score=nan total time=   0.1s\n",
            "[CV 3/5] END .....criterion=log_loss, max_depth=4;, score=nan total time=   0.0s\n",
            "[CV 4/5] END .....criterion=log_loss, max_depth=4;, score=nan total time=   0.0s\n",
            "[CV 5/5] END .....criterion=log_loss, max_depth=4;, score=nan total time=   0.0s\n",
            "[CV 1/5] END .....criterion=log_loss, max_depth=5;, score=nan total time=   0.0s\n",
            "[CV 2/5] END .....criterion=log_loss, max_depth=5;, score=nan total time=   0.0s\n",
            "[CV 3/5] END .....criterion=log_loss, max_depth=5;, score=nan total time=   0.0s\n",
            "[CV 4/5] END .....criterion=log_loss, max_depth=5;, score=nan total time=   0.0s\n",
            "[CV 5/5] END .....criterion=log_loss, max_depth=5;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "20 fits failed out of a total of 60.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "20 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
            "    trees = Parallel(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
            "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
            "    super().fit(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
            "    criterion = CRITERIA_CLF[self.criterion](\n",
            "KeyError: 'log_loss'\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.76917808 0.79939117 0.82138508 0.86255708 0.78013699 0.79383562\n",
            " 0.82682648 0.86799848        nan        nan        nan        nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "[CV 1/5] END .......criterion=gini, max_depth=2;, score=0.575 total time=   0.0s\n",
            "[CV 2/5] END .......criterion=gini, max_depth=2;, score=0.589 total time=   0.0s\n",
            "[CV 3/5] END .......criterion=gini, max_depth=2;, score=0.575 total time=   0.0s\n",
            "[CV 4/5] END .......criterion=gini, max_depth=2;, score=0.575 total time=   0.0s\n",
            "[CV 5/5] END .......criterion=gini, max_depth=2;, score=0.569 total time=   0.0s\n",
            "[CV 1/5] END .......criterion=gini, max_depth=3;, score=0.795 total time=   0.0s\n",
            "[CV 2/5] END .......criterion=gini, max_depth=3;, score=0.712 total time=   0.0s\n",
            "[CV 3/5] END .......criterion=gini, max_depth=3;, score=0.726 total time=   0.0s\n",
            "[CV 4/5] END .......criterion=gini, max_depth=3;, score=0.781 total time=   0.0s\n",
            "[CV 5/5] END .......criterion=gini, max_depth=3;, score=0.750 total time=   0.0s\n",
            "[CV 1/5] END .......criterion=gini, max_depth=4;, score=0.822 total time=   0.0s\n",
            "[CV 2/5] END .......criterion=gini, max_depth=4;, score=0.877 total time=   0.0s\n",
            "[CV 3/5] END .......criterion=gini, max_depth=4;, score=0.890 total time=   0.0s\n",
            "[CV 4/5] END .......criterion=gini, max_depth=4;, score=0.808 total time=   0.0s\n",
            "[CV 5/5] END .......criterion=gini, max_depth=4;, score=0.819 total time=   0.0s\n",
            "[CV 1/5] END .......criterion=gini, max_depth=5;, score=0.808 total time=   0.0s\n",
            "[CV 2/5] END .......criterion=gini, max_depth=5;, score=0.863 total time=   0.0s\n",
            "[CV 3/5] END .......criterion=gini, max_depth=5;, score=0.863 total time=   0.0s\n",
            "[CV 4/5] END .......criterion=gini, max_depth=5;, score=0.781 total time=   0.0s\n",
            "[CV 5/5] END .......criterion=gini, max_depth=5;, score=0.819 total time=   0.0s\n",
            "[CV 1/5] END ....criterion=entropy, max_depth=2;, score=0.562 total time=   0.0s\n",
            "[CV 2/5] END ....criterion=entropy, max_depth=2;, score=0.548 total time=   0.0s\n",
            "[CV 3/5] END ....criterion=entropy, max_depth=2;, score=0.575 total time=   0.0s\n",
            "[CV 4/5] END ....criterion=entropy, max_depth=2;, score=0.575 total time=   0.0s\n",
            "[CV 5/5] END ....criterion=entropy, max_depth=2;, score=0.569 total time=   0.0s\n",
            "[CV 1/5] END ....criterion=entropy, max_depth=3;, score=0.808 total time=   0.0s\n",
            "[CV 2/5] END ....criterion=entropy, max_depth=3;, score=0.671 total time=   0.0s\n",
            "[CV 3/5] END ....criterion=entropy, max_depth=3;, score=0.740 total time=   0.0s\n",
            "[CV 4/5] END ....criterion=entropy, max_depth=3;, score=0.808 total time=   0.0s\n",
            "[CV 5/5] END ....criterion=entropy, max_depth=3;, score=0.750 total time=   0.0s\n",
            "[CV 1/5] END ....criterion=entropy, max_depth=4;, score=0.849 total time=   0.0s\n",
            "[CV 2/5] END ....criterion=entropy, max_depth=4;, score=0.836 total time=   0.0s\n",
            "[CV 3/5] END ....criterion=entropy, max_depth=4;, score=0.863 total time=   0.0s\n",
            "[CV 4/5] END ....criterion=entropy, max_depth=4;, score=0.767 total time=   0.0s\n",
            "[CV 5/5] END ....criterion=entropy, max_depth=4;, score=0.806 total time=   0.0s\n",
            "[CV 1/5] END ....criterion=entropy, max_depth=5;, score=0.795 total time=   0.0s\n",
            "[CV 2/5] END ....criterion=entropy, max_depth=5;, score=0.836 total time=   0.0s\n",
            "[CV 3/5] END ....criterion=entropy, max_depth=5;, score=0.849 total time=   0.0s\n",
            "[CV 4/5] END ....criterion=entropy, max_depth=5;, score=0.753 total time=   0.0s\n",
            "[CV 5/5] END ....criterion=entropy, max_depth=5;, score=0.806 total time=   0.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNuBE-CSolcJ",
        "outputId": "7ea000be-42e7-4076-ffd4-ee2efbf523e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'model': 'SVC',\n",
              "  'best_score': 0.8405631659056316,\n",
              "  'best_params': {'C': 100, 'kernel': 'rbf'}},\n",
              " {'model': 'Logistic_Regession',\n",
              "  'best_score': 0.8132420091324202,\n",
              "  'best_params': {'penalty': 'none', 'solver': 'newton-cg'}},\n",
              " {'model': 'Random_Forest',\n",
              "  'best_score': 0.8679984779299847,\n",
              "  'best_params': {'criterion': 'entropy', 'max_depth': 5}},\n",
              " {'model': 'Decision_Tree',\n",
              "  'best_score': 0.8433409436834095,\n",
              "  'best_params': {'criterion': 'gini', 'max_depth': 4}}]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(best_params,columns=['model','best_score','best_params'])"
      ],
      "metadata": {
        "id": "djMeBNKVpQed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "rZEMEQHIpQmU",
        "outputId": "e4f81134-bb12-4310-f8bd-8d8b9b1001f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                model  best_score                                 best_params\n",
              "0                 SVC    0.840563                 {'C': 100, 'kernel': 'rbf'}\n",
              "1  Logistic_Regession    0.813242  {'penalty': 'none', 'solver': 'newton-cg'}\n",
              "2       Random_Forest    0.867998    {'criterion': 'entropy', 'max_depth': 5}\n",
              "3       Decision_Tree    0.843341       {'criterion': 'gini', 'max_depth': 4}"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8dd702b4-a060-4d9b-a1be-2d502a57bc9c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>best_score</th>\n",
              "      <th>best_params</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.840563</td>\n",
              "      <td>{'C': 100, 'kernel': 'rbf'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic_Regession</td>\n",
              "      <td>0.813242</td>\n",
              "      <td>{'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random_Forest</td>\n",
              "      <td>0.867998</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 5}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Decision_Tree</td>\n",
              "      <td>0.843341</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 4}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8dd702b4-a060-4d9b-a1be-2d502a57bc9c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8dd702b4-a060-4d9b-a1be-2d502a57bc9c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8dd702b4-a060-4d9b-a1be-2d502a57bc9c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ANN with 3 Dense Layers"
      ],
      "metadata": {
        "id": "IXhxUWp3ZXt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Resplit the data without fixing the imbalance"
      ],
      "metadata": {
        "id": "v9RwMO5Q1R0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = glass.drop('Type', axis = 1)\n",
        "y = glass['Type']"
      ],
      "metadata": {
        "id": "TI6VA2U-0YsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = .2, random_state = 42, stratify = y)"
      ],
      "metadata": {
        "id": "lvhfDvFJ0Yyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scaling data"
      ],
      "metadata": {
        "id": "W-F9TXZNaqrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "0W89Waj-XyA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### building ANN Model"
      ],
      "metadata": {
        "id": "NCXNw594a53U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "mOeo8To0asdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(unit):\n",
        "  #Creating the layers of the NN\n",
        "  model = Sequential()\n",
        "  model.add(Dense(units = unit, activation = 'relu', input_shape = (9,)))\n",
        "  model.add(Dense(units = unit, activation = 'relu'))\n",
        "  model.add(Dense(units = unit, activation = 'softmax'))\n",
        "  model.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "  model.compile(optimizer = 'adam', loss  = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "_eREjHQia-S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "model = KerasClassifier(build_fn = build_model)"
      ],
      "metadata": {
        "id": "ASEIOpZncg13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "179559d0-bfcc-49d8-c9e5-2a8cacfb7742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-267db9bfadcf>:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn = build_model)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'batch_size':[1,3,5,10,20],\n",
        "          'nb_epoch':[1,5,10,30,50,100],\n",
        "          'unit':[3,5,10,15,20]}"
      ],
      "metadata": {
        "id": "59rV5fTpctou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid Search for best parameters and score"
      ],
      "metadata": {
        "id": "L7mqgSZmc_C0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search = GridSearchCV(estimator = model, param_grid = params)\n",
        "grid_search = grid_search.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "DIOsGZO8czno",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b8d6f59-d2f8-4b7b-cec9-cb203f86cc61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "136/136 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.3750\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4248 - accuracy: 0.2857 \n",
            "137/137 [==============================] - 1s 2ms/step - loss: -0.0458 - accuracy: 0.3285\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.3130 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 1.4475 - accuracy: 0.3285\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 1.1863 - accuracy: 0.3235\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.8887 - accuracy: 0.3212\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.8644 - accuracy: 0.3529\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.1704 - accuracy: 0.3650\n",
            "34/34 [==============================] - 0s 2ms/step - loss: -0.0975 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 1.0376 - accuracy: 0.3162\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.9038 - accuracy: 0.3714\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.0717 - accuracy: 0.3285\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.3705 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.7677 - accuracy: 0.3650\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.6609 - accuracy: 0.4118\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.4713 - accuracy: 0.3796\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2245 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 1.1964 - accuracy: 0.3504\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 1.1978 - accuracy: 0.2353\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.6351 - accuracy: 0.3971\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.2857 \n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.4875 - accuracy: 0.3285\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.7620 - accuracy: 0.3212\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.3529\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.4710 - accuracy: 0.3723\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2556 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5608 - accuracy: 0.3650\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4078 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.5397 - accuracy: 0.3382\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.3031 - accuracy: 0.2857 \n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.2931 - accuracy: 0.3285\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4147 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.4652 - accuracy: 0.3358\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4193 - accuracy: 0.4412\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.3796\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.2088 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6392 - accuracy: 0.3723\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4753 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.4977 - accuracy: 0.3676\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.2656 - accuracy: 0.2857 \n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5466 - accuracy: 0.3212\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5375 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.4281 - accuracy: 0.3285\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.3527 - accuracy: 0.4412\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6043 - accuracy: 0.3577\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6961 - accuracy: 0.3796\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.0251 - accuracy: 0.3750\n",
            "35/35 [==============================] - 0s 1ms/step - loss: -0.2233 - accuracy: 0.2857\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.3221 - accuracy: 0.3285\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4410 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.1802 - accuracy: 0.3358\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.4412\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.3111 - accuracy: 0.3796\n",
            "34/34 [==============================] - 0s 1ms/step - loss: -0.1082 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.3878 - accuracy: 0.3577\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.8423 - accuracy: 0.3162\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.7425 - accuracy: 0.3714\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.9890 - accuracy: 0.2920\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.6759 - accuracy: 0.3529\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.4059 - accuracy: 0.3358\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.3792 - accuracy: 0.4412\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.8969 - accuracy: 0.3212\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.8186 - accuracy: 0.3529\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6121 - accuracy: 0.3723\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.2647\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.4412 - accuracy: 0.3750\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2932 - accuracy: 0.2857\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6473 - accuracy: 0.3358\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.6062 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.7682 - accuracy: 0.2847\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.6177 - accuracy: 0.4412\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5447 - accuracy: 0.3723\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.3411 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5472 - accuracy: 0.3066\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.3440 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.6080 - accuracy: 0.3603\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.3602 - accuracy: 0.2857 \n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5393 - accuracy: 0.3066\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.8512 - accuracy: 0.3285\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.7075 - accuracy: 0.3235\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5527 - accuracy: 0.3796\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.3138 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6017 - accuracy: 0.4015\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.3832 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.6511 - accuracy: 0.3824\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.2857\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.4453 - accuracy: 0.3285\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6378 - accuracy: 0.3285\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.4412\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6251 - accuracy: 0.3431\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2727 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6060 - accuracy: 0.3723\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.3750 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.9143 - accuracy: 0.3309\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.7074 - accuracy: 0.2857\n",
            "137/137 [==============================] - 1s 2ms/step - loss: -0.0429 - accuracy: 0.3285\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2991 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 1.2423 - accuracy: 0.3285\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 1.0375 - accuracy: 0.3235\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.3210 - accuracy: 0.3796\n",
            "34/34 [==============================] - 0s 1ms/step - loss: -0.1931 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.2395 - accuracy: 0.3650\n",
            "34/34 [==============================] - 0s 1ms/step - loss: -0.0706 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.3710 - accuracy: 0.3750\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.2857 \n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.3078 - accuracy: 0.3212\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4325 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.3909 - accuracy: 0.3358\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.4412\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.9756 - accuracy: 0.3212\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.9782 - accuracy: 0.3529\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.3874 - accuracy: 0.3504\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.0251 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.4216 - accuracy: 0.3750\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1726 - accuracy: 0.2857 \n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.7528 - accuracy: 0.3139\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.1974 - accuracy: 0.3358\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.4412\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.8092 - accuracy: 0.3504\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.6255 - accuracy: 0.2941\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.7829 - accuracy: 0.3723\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.6765 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.6183 - accuracy: 0.3382\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.2857\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5584 - accuracy: 0.3139\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5313 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6776 - accuracy: 0.3358\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5785 - accuracy: 0.4412\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5873 - accuracy: 0.3796\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.3589 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5577 - accuracy: 0.3577\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.5264 - accuracy: 0.3750\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.3674 - accuracy: 0.2857 \n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.4969 - accuracy: 0.3139\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5304 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.4974 - accuracy: 0.3285\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4214 - accuracy: 0.4412\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.4449 - accuracy: 0.3796\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.0639 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.4280 - accuracy: 0.3650\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.1358 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.9292 - accuracy: 0.3162\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.7252 - accuracy: 0.3714 \n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.3652 - accuracy: 0.3139\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5091 - accuracy: 0.4412\n",
            "137/137 [==============================] - 1s 2ms/step - loss: -0.1623 - accuracy: 0.3358\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.0372 - accuracy: 0.4412\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.3875 - accuracy: 0.3796\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.1479 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.1740 - accuracy: 0.3650\n",
            "34/34 [==============================] - 0s 1ms/step - loss: -0.1047 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.2252 - accuracy: 0.3750\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.2857\n",
            "137/137 [==============================] - 2s 2ms/step - loss: 0.4479 - accuracy: 0.3504\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 3ms/step - loss: 1.0316 - accuracy: 0.3285\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.8010 - accuracy: 0.3235\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6776 - accuracy: 0.3869\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 1.2999 - accuracy: 0.3504\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1.3488 - accuracy: 0.2353\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.5319 - accuracy: 0.3750\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.3920 - accuracy: 0.2857 \n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.2136 - accuracy: 0.3285\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4028 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.8304 - accuracy: 0.3358\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.7231 - accuracy: 0.3235\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5854 - accuracy: 0.3723\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.3358 - accuracy: 0.3650\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.0818 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.4194 - accuracy: 0.3750\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2579 - accuracy: 0.2857\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6225 - accuracy: 0.3066\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5929 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.3869\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5607 - accuracy: 0.4412\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.3829 - accuracy: 0.3796\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5516 - accuracy: 0.3212\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2806 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.5559 - accuracy: 0.4044\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.2857 \n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6975 - accuracy: 0.3650\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.6235 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5177 - accuracy: 0.3358\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4300 - accuracy: 0.4412\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5759 - accuracy: 0.3723\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.7534 - accuracy: 0.3869\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.6350 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: -0.1113 - accuracy: 0.3750\n",
            "35/35 [==============================] - 0s 2ms/step - loss: -0.2236 - accuracy: 0.2857\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 1.4111 - accuracy: 0.3212\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 1.0211 - accuracy: 0.3529\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 1.6271 - accuracy: 0.3285\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 1.3385 - accuracy: 0.3235\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6050 - accuracy: 0.3942\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.2062 - accuracy: 0.3650\n",
            "34/34 [==============================] - 0s 2ms/step - loss: -0.0473 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.6522 - accuracy: 0.3529\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4069 - accuracy: 0.4000 \n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.1906 - accuracy: 0.3285\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.3782 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.7627 - accuracy: 0.3212\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.6573 - accuracy: 0.4118\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5764 - accuracy: 0.3796\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.3823 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.7746 - accuracy: 0.3869\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.6645 - accuracy: 0.3529\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.5205 - accuracy: 0.3750\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.2857\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.7893 - accuracy: 0.2774\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.6226 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.3358\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.3417 - accuracy: 0.4412\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.7713 - accuracy: 0.3869\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6079 - accuracy: 0.3824\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6915 - accuracy: 0.3212\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.4721 - accuracy: 0.3750\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1968 - accuracy: 0.2857 \n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.4648 - accuracy: 0.3285\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5554 - accuracy: 0.3358\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.4412\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6796 - accuracy: 0.3358\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6917 - accuracy: 0.4526\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5376 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.6852 - accuracy: 0.3382\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5084 - accuracy: 0.2857 \n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.4786 - accuracy: 0.3285\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.3139\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.4412\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6682 - accuracy: 0.4234\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.3770 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.7246 - accuracy: 0.3577\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5304 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: -0.2401 - accuracy: 0.3750\n",
            "35/35 [==============================] - 0s 1ms/step - loss: -0.3403 - accuracy: 0.2857\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6596 - accuracy: 0.2847\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6464 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.7623 - accuracy: 0.3504\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.6369 - accuracy: 0.3824\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.9335 - accuracy: 0.3212\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.9253 - accuracy: 0.3529\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.3644 - accuracy: 0.3650\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.1512 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.8237 - accuracy: 0.3456\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7877 - accuracy: 0.4571\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.2835 - accuracy: 0.3285\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.9747 - accuracy: 0.3431\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.7731 - accuracy: 0.3529\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6100 - accuracy: 0.3504\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.3052 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5504 - accuracy: 0.3577\n",
            "34/34 [==============================] - 1s 2ms/step - loss: 0.3428 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.5156 - accuracy: 0.3750\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.3908 - accuracy: 0.2857 \n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6881 - accuracy: 0.3285\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5835 - accuracy: 0.3212\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4928 - accuracy: 0.4412\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5779 - accuracy: 0.3431\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4105 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5550 - accuracy: 0.3650\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.3758 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.8062 - accuracy: 0.3162\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6978 - accuracy: 0.4000\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.3755 - accuracy: 0.3285\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5756 - accuracy: 0.3066\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4727 - accuracy: 0.4412\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5175 - accuracy: 0.3942\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.1289 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.4970 - accuracy: 0.2920\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2575 - accuracy: 0.3235\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 0.4226 - accuracy: 0.3750\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.2857\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5152 - accuracy: 0.3139\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.4706\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.4689 - accuracy: 0.3358\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.4412\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.5045 - accuracy: 0.3796\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.2255 - accuracy: 0.2647\n",
            "137/137 [==============================] - 1s 2ms/step - loss: 0.6163 - accuracy: 0.3723\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.3750\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.2857\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.0541 - accuracy: 0.3285\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.4706\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 1.7422 - accuracy: 0.3285\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.4662 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.2369 - accuracy: 0.3796\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -0.1291 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.2213 - accuracy: 0.3650\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -0.1067 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.1101 - accuracy: 0.3750\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 0.2857 \n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.2005 - accuracy: 0.3285\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.4706\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 1.1058 - accuracy: 0.3285\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9858 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.9671 - accuracy: 0.3212\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0573 - accuracy: 0.3529\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.7305 - accuracy: 0.3504\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.2353\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.5177 - accuracy: 0.3676\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.2857\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.7937 - accuracy: 0.3139\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7021 - accuracy: 0.3824\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.4500 - accuracy: 0.3358\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.4412\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.3773 - accuracy: 0.3796\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.4465 - accuracy: 0.3650\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.7134 - accuracy: 0.3162\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6215 - accuracy: 0.2000\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6285 - accuracy: 0.3212\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.4706\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.5295 - accuracy: 0.3358\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.4412\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.4710 - accuracy: 0.3796\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2895 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.8371 - accuracy: 0.3504\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7715 - accuracy: 0.2353\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.5207 - accuracy: 0.3750\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.2857\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.4673 - accuracy: 0.3285\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.4706\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6259 - accuracy: 0.4161\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6008 - accuracy: 0.4412\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6720 - accuracy: 0.3139\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6336 - accuracy: 0.3796\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6261 - accuracy: 0.2426\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.2286\n",
            "46/46 [==============================] - 1s 2ms/step - loss: -0.0205 - accuracy: 0.3285\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.4706\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.7652 - accuracy: 0.3577\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7053 - accuracy: 0.3824\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.9924 - accuracy: 0.3212\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0384 - accuracy: 0.3529\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.0537 - accuracy: 0.3650\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -0.2227 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.8728 - accuracy: 0.3235\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8473 - accuracy: 0.3714\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 1.1145 - accuracy: 0.3212\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8659 - accuracy: 0.3529\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.4205 - accuracy: 0.3358\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.4412\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.3920 - accuracy: 0.3796\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2680 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 1.0222 - accuracy: 0.3504\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0050 - accuracy: 0.2353\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.7387 - accuracy: 0.2868\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.2571\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6363 - accuracy: 0.3358\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.5000\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.7255 - accuracy: 0.3431\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.6471\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.4994 - accuracy: 0.3796\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2275 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.7084 - accuracy: 0.4015\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.7234 - accuracy: 0.3309\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6013 - accuracy: 0.2857\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6278 - accuracy: 0.3285\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.4706\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.5268 - accuracy: 0.3358\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.4412\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6435 - accuracy: 0.3504\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.8462 - accuracy: 0.3504\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8248 - accuracy: 0.2353\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6909 - accuracy: 0.3382\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6221 - accuracy: 0.2857\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6207 - accuracy: 0.3212\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.4706\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.5891 - accuracy: 0.3285\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.4412\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.5984 - accuracy: 0.3796\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.5752 - accuracy: 0.3650\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.3490 - accuracy: 0.3456\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.2857\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.4510 - accuracy: 0.3285\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.4706\n",
            "46/46 [==============================] - 1s 2ms/step - loss: -0.1410 - accuracy: 0.3358\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.4412\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 1.5541 - accuracy: 0.3212\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.8256 - accuracy: 0.3529\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.9993 - accuracy: 0.3504\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0650 - accuracy: 0.2353\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.7732 - accuracy: 0.3235\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.4000\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 1.1629 - accuracy: 0.3212\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8826 - accuracy: 0.3529\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 1.2251 - accuracy: 0.3285\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9876 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.4353 - accuracy: 0.3796\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1522 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.5688 - accuracy: 0.3577\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.4739 - accuracy: 0.3676\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.2857\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.5679 - accuracy: 0.2993\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.5000\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.5753 - accuracy: 0.3431\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.4412\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.7025 - accuracy: 0.3285\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.9612 - accuracy: 0.3504\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9985 - accuracy: 0.2353\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.5799 - accuracy: 0.3750\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.2857\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.4949 - accuracy: 0.3285\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.4706\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.4684 - accuracy: 0.3358\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.4412\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6487 - accuracy: 0.3504\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6418 - accuracy: 0.3650\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.5921 - accuracy: 0.3750\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.2857\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6052 - accuracy: 0.3285\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5994 - accuracy: 0.4706\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6202 - accuracy: 0.3358\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.4412\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.3796\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6839 - accuracy: 0.3431\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5932 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6649 - accuracy: 0.2721\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.2857\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6830 - accuracy: 0.3139\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6790 - accuracy: 0.4706\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.3013 - accuracy: 0.3358\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.4412\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.2673 - accuracy: 0.3796\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -0.0509 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.9742 - accuracy: 0.3504\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8989 - accuracy: 0.2353\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6106 - accuracy: 0.3750\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.2857\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.9846 - accuracy: 0.3212\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8084 - accuracy: 0.3529\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.9224 - accuracy: 0.3285\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8135 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 1.0295 - accuracy: 0.3212\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0744 - accuracy: 0.3529\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.7152 - accuracy: 0.4088\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.2941\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.4874 - accuracy: 0.3824\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.2857\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.4299 - accuracy: 0.3285\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.4706\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.3451 - accuracy: 0.3358\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4011 - accuracy: 0.4412\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.4875 - accuracy: 0.3796\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2286 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6445 - accuracy: 0.3796\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.4929 - accuracy: 0.3750\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.2857\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.8422 - accuracy: 0.3285\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6997 - accuracy: 0.4706\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6172 - accuracy: 0.3358\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.4412\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.8149 - accuracy: 0.3212\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7901 - accuracy: 0.3529\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.5617 - accuracy: 0.3650\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.6336 - accuracy: 0.3529\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.2857\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.5822 - accuracy: 0.3285\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.4706\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6272 - accuracy: 0.2920\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.4412\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.5264 - accuracy: 0.3796\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6634 - accuracy: 0.3577\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5754 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 1.5709 - accuracy: 0.3162\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.5330 - accuracy: 0.3714\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 1.7782 - accuracy: 0.3212\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2416 - accuracy: 0.3529\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.2677 - accuracy: 0.3139\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.4118\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.4364 - accuracy: 0.3796\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.1548 - accuracy: 0.3650\n",
            "12/12 [==============================] - 0s 2ms/step - loss: -0.0956 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.3250 - accuracy: 0.3750\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2346 - accuracy: 0.2857\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.4063 - accuracy: 0.3285\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.4706\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.8240 - accuracy: 0.3431\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7654 - accuracy: 0.3529\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6280 - accuracy: 0.3577\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.7746 - accuracy: 0.3139\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.4271 - accuracy: 0.3750\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.2857\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.8713 - accuracy: 0.3212\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7517 - accuracy: 0.3824\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.4808 - accuracy: 0.3285\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.4412\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6605 - accuracy: 0.3796\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.4706\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6597 - accuracy: 0.3796\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6948 - accuracy: 0.3603\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.2857\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.8005 - accuracy: 0.3212\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7001 - accuracy: 0.3529\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.4854 - accuracy: 0.3358\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.4412\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.5399 - accuracy: 0.3796\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6148 - accuracy: 0.3504\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.6303 - accuracy: 0.3750\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.2857\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.5865 - accuracy: 0.3358\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.4706\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.5642 - accuracy: 0.3358\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.4412\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.6991 - accuracy: 0.3504\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.6832 - accuracy: 0.3723\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.1345 - accuracy: 0.3750\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.2857\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.6478 - accuracy: 0.3285\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.4706\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.3358\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.4412\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.3179 - accuracy: 0.3796\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1403 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 1.1189 - accuracy: 0.3577\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8579 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.5476 - accuracy: 0.3676\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.5143\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.7413 - accuracy: 0.3212\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4118\n",
            "46/46 [==============================] - 1s 2ms/step - loss: -0.0762 - accuracy: 0.3358\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1227 - accuracy: 0.4412\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.3796\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1218 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.7230 - accuracy: 0.4380\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.3824\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6254 - accuracy: 0.3456\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.2857\n",
            "46/46 [==============================] - 1s 4ms/step - loss: 0.5070 - accuracy: 0.3285\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.4706\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.3212\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.4412\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.7232 - accuracy: 0.3139\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6992 - accuracy: 0.2941\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.7883 - accuracy: 0.3577\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7488 - accuracy: 0.1765\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.5122 - accuracy: 0.3750\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.2857\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.6377 - accuracy: 0.3285\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.4706\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.5722 - accuracy: 0.3358\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.4412\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.7158 - accuracy: 0.3796\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.2353\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.5262 - accuracy: 0.3650\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.3235\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6008 - accuracy: 0.3750\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.2857\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.5606 - accuracy: 0.3212\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5829 - accuracy: 0.4706\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.5841 - accuracy: 0.3358\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.4412\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6713 - accuracy: 0.3358\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.2647\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.5593 - accuracy: 0.3650\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.6239 - accuracy: 0.3603\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5462 - accuracy: 0.2857\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.5015 - accuracy: 0.3212\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.4706\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.0581 - accuracy: 0.3358\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2054 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.3898 - accuracy: 0.3796\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2685 - accuracy: 0.2647\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.9715 - accuracy: 0.3796\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.0055 - accuracy: 0.2353\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.6509 - accuracy: 0.3603\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6168 - accuracy: 0.2857\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.3298 - accuracy: 0.3285\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.4706\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.9917 - accuracy: 0.3285\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.9115 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.2994 - accuracy: 0.3796\n",
            "7/7 [==============================] - 0s 2ms/step - loss: -0.0509 - accuracy: 0.2647\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.8592 - accuracy: 0.3285\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.9079 - accuracy: 0.2059\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.8324 - accuracy: 0.3162\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7849 - accuracy: 0.3714\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.8906 - accuracy: 0.3212\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7690 - accuracy: 0.3529\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.3912 - accuracy: 0.3358\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6619 - accuracy: 0.3723\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.2647\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.3210 - accuracy: 0.3650\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.1373 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.8310 - accuracy: 0.3162\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.8004 - accuracy: 0.3714\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6239 - accuracy: 0.3723\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.4118\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.4250 - accuracy: 0.3358\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6673 - accuracy: 0.3577\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.2647\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6170 - accuracy: 0.3650\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.7109 - accuracy: 0.3529\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6244 - accuracy: 0.3429\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.7571 - accuracy: 0.3358\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.4118\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6843 - accuracy: 0.3431\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6289 - accuracy: 0.3796\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.2647\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.5831 - accuracy: 0.3650\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 2ms/step - loss: -0.1552 - accuracy: 0.3750\n",
            "7/7 [==============================] - 0s 2ms/step - loss: -0.2351 - accuracy: 0.2857\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.9334 - accuracy: 0.3212\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.8265 - accuracy: 0.3529\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.5898 - accuracy: 0.3577\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.4370 - accuracy: 0.3796\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.2542 - accuracy: 0.2647\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.6625 - accuracy: 0.4307\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6212 - accuracy: 0.3529\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.7697 - accuracy: 0.3824\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7007 - accuracy: 0.4571\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.1825 - accuracy: 0.3431\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.4706\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.2775 - accuracy: 0.3358\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.7457 - accuracy: 0.3139\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7798 - accuracy: 0.4118\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.6379 - accuracy: 0.3285\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5308 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.4564 - accuracy: 0.3750\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3700 - accuracy: 0.2857\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.5289 - accuracy: 0.3285\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.4706\n",
            "28/28 [==============================] - 1s 4ms/step - loss: 0.5684 - accuracy: 0.3358\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5853 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6511 - accuracy: 0.3650\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.2647\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.5422 - accuracy: 0.3504\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6832 - accuracy: 0.3750\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6020 - accuracy: 0.2857\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.4863 - accuracy: 0.3285\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.4706\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.7574 - accuracy: 0.2920\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.4118\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.7218 - accuracy: 0.3358\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5973 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6619 - accuracy: 0.3504\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6050 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6152 - accuracy: 0.3676\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.2857\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.5796 - accuracy: 0.3285\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6117 - accuracy: 0.4706\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.5202 - accuracy: 0.3358\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6641 - accuracy: 0.3869\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.2647\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.5315 - accuracy: 0.3650\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.8329 - accuracy: 0.3162\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.7976 - accuracy: 0.3714\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.0404 - accuracy: 0.3285 \n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3786 - accuracy: 0.4706\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.0299 - accuracy: 0.3358\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2669 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.7511 - accuracy: 0.3577\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6746 - accuracy: 0.2353\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.7175 - accuracy: 0.3358\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.7336 - accuracy: 0.1176\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.6644 - accuracy: 0.3603\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.5919 - accuracy: 0.2857\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.9393 - accuracy: 0.3212\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7997 - accuracy: 0.3529\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.5984 - accuracy: 0.3066\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.4118\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.5518 - accuracy: 0.3796\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.2647\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.2889 - accuracy: 0.3650\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1050 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6211 - accuracy: 0.3750\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.2857\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.8746 - accuracy: 0.3212\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.7612 - accuracy: 0.3529\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.8071 - accuracy: 0.3285\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.4110 - accuracy: 0.3796\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.1296 - accuracy: 0.2647\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.4526 - accuracy: 0.3650\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3594 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6608 - accuracy: 0.3456\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.1714\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.8504 - accuracy: 0.3212\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7458 - accuracy: 0.3529\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6394 - accuracy: 0.2774\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6455 - accuracy: 0.4118\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6135 - accuracy: 0.3869\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.2647\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.7147 - accuracy: 0.3723\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.6395 - accuracy: 0.2647\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.7778 - accuracy: 0.3235\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7107 - accuracy: 0.3714\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.7004 - accuracy: 0.3650\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.6832 - accuracy: 0.3285\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6463 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.7283 - accuracy: 0.3212\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6406 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.5707 - accuracy: 0.3650\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 1.2320 - accuracy: 0.3162\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.1922 - accuracy: 0.3714\n",
            "28/28 [==============================] - 1s 2ms/step - loss: -0.4248 - accuracy: 0.3285\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.4706\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.5221 - accuracy: 0.3212\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.5646 - accuracy: 0.3796\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.2647\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.3963 - accuracy: 0.3650\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.8552 - accuracy: 0.3162\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.8424 - accuracy: 0.3714\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.8074 - accuracy: 0.3212\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7293 - accuracy: 0.3529\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.9894 - accuracy: 0.3285 \n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.8927 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.3860 - accuracy: 0.3796\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.2368 - accuracy: 0.2647\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.6577 - accuracy: 0.3869\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5960 - accuracy: 0.3824\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6632 - accuracy: 0.3529\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6090 - accuracy: 0.2571\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6999 - accuracy: 0.2993\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6830 - accuracy: 0.4706\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.9835 - accuracy: 0.3285\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.8767 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.8838 - accuracy: 0.3212\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.9213 - accuracy: 0.3529\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.4862 - accuracy: 0.3650\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3501 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.5722 - accuracy: 0.3603\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.2857\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.5805 - accuracy: 0.3285\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6159 - accuracy: 0.4706\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6891 - accuracy: 0.3577\n",
            "7/7 [==============================] - 1s 5ms/step - loss: 0.6398 - accuracy: 0.5000\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.7322 - accuracy: 0.3212\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.6911 - accuracy: 0.3529\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6322 - accuracy: 0.3650\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.7030 - accuracy: 0.3897\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.2857\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6467 - accuracy: 0.3431\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.4706\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.7515 - accuracy: 0.3285\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6982 - accuracy: 0.3529\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.5658 - accuracy: 0.3796\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.2647\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6265 - accuracy: 0.3650\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.7529 - accuracy: 0.3088\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.4286\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.2428 - accuracy: 0.3212  \n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.4706\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.5847 - accuracy: 0.3577\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.6943 - accuracy: 0.3139\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.8006 - accuracy: 0.2059\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.6549 - accuracy: 0.3504\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6020 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 5ms/step - loss: 0.9098 - accuracy: 0.3162\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.8448 - accuracy: 0.3714\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 1.0270 - accuracy: 0.3650\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.8102 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.5544 - accuracy: 0.3358 \n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.6784 - accuracy: 0.3504\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.2353\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.5977 - accuracy: 0.3139\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.5440 - accuracy: 0.3750\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.2857\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6867 - accuracy: 0.3650\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6632 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.4940 - accuracy: 0.3358\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6387 - accuracy: 0.3723\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5465 - accuracy: 0.2647\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.7109 - accuracy: 0.3796\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6666 - accuracy: 0.2941\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.7174 - accuracy: 0.3529\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.4571\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6070 - accuracy: 0.3212\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.4706\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6052 - accuracy: 0.3358\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 4ms/step - loss: 0.5847 - accuracy: 0.3796\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.2647\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.5382 - accuracy: 0.3650\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6373 - accuracy: 0.3750\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.2857\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.7034 - accuracy: 0.3723\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6642 - accuracy: 0.4706\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6835 - accuracy: 0.3504\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6477 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6461 - accuracy: 0.3796\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.2647\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6054 - accuracy: 0.3650\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.1615 - accuracy: 0.3750\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.1083 - accuracy: 0.2857\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.3134 - accuracy: 0.3285\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.4706\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.1932 - accuracy: 0.3358\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.2866 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6739 - accuracy: 0.3723\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.2647\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 1.6586 - accuracy: 0.3504\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.9474 - accuracy: 0.2353\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.4433 - accuracy: 0.3750\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3776 - accuracy: 0.2857\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.6800 - accuracy: 0.3212\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.6646 - accuracy: 0.4118\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.5622 - accuracy: 0.3358\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5375 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.8524 - accuracy: 0.3212\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7886 - accuracy: 0.3529\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.5229 - accuracy: 0.4015\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.3235\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.8084 - accuracy: 0.3235\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.7814 - accuracy: 0.3714\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.8468 - accuracy: 0.3212\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7525 - accuracy: 0.3529\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6426 - accuracy: 0.3358\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.4118\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.8834 - accuracy: 0.3212\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.8913 - accuracy: 0.3529\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6665 - accuracy: 0.3796\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.2941\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6143 - accuracy: 0.3529\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5322 - accuracy: 0.2857\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.5661 - accuracy: 0.3504\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6004 - accuracy: 0.4706\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.4935 - accuracy: 0.3285\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.8808 - accuracy: 0.3212\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.9025 - accuracy: 0.3529\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.7487 - accuracy: 0.4015\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6780 - accuracy: 0.2941\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6973 - accuracy: 0.3309\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.6242 - accuracy: 0.2857\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.5905 - accuracy: 0.3285\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6131 - accuracy: 0.4706\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.5947 - accuracy: 0.3358\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.4412\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6720 - accuracy: 0.3212\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6027 - accuracy: 0.2647\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.5937 - accuracy: 0.3650\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 0.5015 - accuracy: 0.3529\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.4000\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 1.2933 - accuracy: 0.3212\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0117 - accuracy: 0.3529\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 0.9249 - accuracy: 0.3285\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8599 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.8208 - accuracy: 0.3212\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.2373 - accuracy: 0.3529\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7982 - accuracy: 0.3504\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7985 - accuracy: 0.2353\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6840 - accuracy: 0.3529\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6677 - accuracy: 0.2857\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.5116 - accuracy: 0.3285\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6180 - accuracy: 0.4706\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.2509 - accuracy: 0.3358\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3627 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.8686 - accuracy: 0.3212\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8904 - accuracy: 0.3529\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 0.6357 - accuracy: 0.3650\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7765 - accuracy: 0.3382\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7884 - accuracy: 0.4000\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.8220 - accuracy: 0.3212\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7488 - accuracy: 0.2647\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.9364 - accuracy: 0.3285\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8503 - accuracy: 0.3529\n",
            "14/14 [==============================] - 1s 4ms/step - loss: 0.5658 - accuracy: 0.3796\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.2647\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.5374 - accuracy: 0.3650\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7677 - accuracy: 0.3235\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7498 - accuracy: 0.3714\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.5975 - accuracy: 0.3285\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6357 - accuracy: 0.4706\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.8575 - accuracy: 0.3285\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7992 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7622 - accuracy: 0.3212\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7187 - accuracy: 0.3529\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7606 - accuracy: 0.3504\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7702 - accuracy: 0.2353\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.5239 - accuracy: 0.3750\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.2857\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6653 - accuracy: 0.3212\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6652 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6836 - accuracy: 0.3723\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6689 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.4752 - accuracy: 0.3796\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3143 - accuracy: 0.2647\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6647 - accuracy: 0.3796\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6278 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 0.5169 - accuracy: 0.3750\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.2857\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 1.3833 - accuracy: 0.3212\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9740 - accuracy: 0.3529\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6197 - accuracy: 0.3431\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.4453 - accuracy: 0.3796\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3345 - accuracy: 0.2647\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 1.2311 - accuracy: 0.3504\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3821 - accuracy: 0.2353\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 1.2583 - accuracy: 0.3162\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.2704 - accuracy: 0.3714\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 1.1091 - accuracy: 0.3212\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9073 - accuracy: 0.3529\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7873 - accuracy: 0.2628\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7457 - accuracy: 0.5000\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 0.5727 - accuracy: 0.3504\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.3529\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7506 - accuracy: 0.3285\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7425 - accuracy: 0.2941\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6358 - accuracy: 0.3603\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6150 - accuracy: 0.2857\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6699 - accuracy: 0.4015\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6536 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6060 - accuracy: 0.3212\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6551 - accuracy: 0.4118\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.5974 - accuracy: 0.3869\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.2941\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.9746 - accuracy: 0.3504\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0329 - accuracy: 0.2353\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6843 - accuracy: 0.3456\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6487 - accuracy: 0.3143\n",
            "14/14 [==============================] - 1s 4ms/step - loss: 0.5983 - accuracy: 0.3212\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6138 - accuracy: 0.4706\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7472 - accuracy: 0.3285\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7126 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.5612 - accuracy: 0.3796\n",
            "4/4 [==============================] - 1s 3ms/step - loss: 0.4013 - accuracy: 0.2647\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6279 - accuracy: 0.3504\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5593 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6947 - accuracy: 0.3456\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6489 - accuracy: 0.4000\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 0.7343 - accuracy: 0.3139\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6960 - accuracy: 0.4118\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.5750 - accuracy: 0.3358\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5701 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7325 - accuracy: 0.3358\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7004 - accuracy: 0.3824\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7743 - accuracy: 0.3504\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7670 - accuracy: 0.2353\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.2648 - accuracy: 0.3750\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1180 - accuracy: 0.2857\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6406 - accuracy: 0.3285\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6322 - accuracy: 0.4706\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6636 - accuracy: 0.3212\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 1.1245 - accuracy: 0.3212\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.1613 - accuracy: 0.3529\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6606 - accuracy: 0.3796\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 0.5621 - accuracy: 0.3676\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.2857\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.2781 - accuracy: 0.3285  \n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.4706\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7337 - accuracy: 0.3431\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7062 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.1514 - accuracy: 0.3796\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -0.0620 - accuracy: 0.2647\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 0.5894 - accuracy: 0.2774\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5466 - accuracy: 0.3529\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7005 - accuracy: 0.3456\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.4286\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.5831 - accuracy: 0.3285\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6209 - accuracy: 0.4706\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6630 - accuracy: 0.3504\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6543 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7094 - accuracy: 0.4380\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5529 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 4ms/step - loss: 0.5659 - accuracy: 0.3650\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 4ms/step - loss: 0.6151 - accuracy: 0.3750\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5744 - accuracy: 0.2857\n",
            "14/14 [==============================] - 1s 4ms/step - loss: 0.6902 - accuracy: 0.3212\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6762 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6688 - accuracy: 0.3358\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7062 - accuracy: 0.3650\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6304 - accuracy: 0.3824\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.8239 - accuracy: 0.3504\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8280 - accuracy: 0.2353\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6222 - accuracy: 0.3750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5815 - accuracy: 0.2857\n",
            "14/14 [==============================] - 1s 4ms/step - loss: 0.6452 - accuracy: 0.2993\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6413 - accuracy: 0.4706\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.8557 - accuracy: 0.3285\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8013 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6014 - accuracy: 0.3796\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.2647\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.5252 - accuracy: 0.3650\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 1.0028 - accuracy: 0.3162\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0063 - accuracy: 0.3714\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 0.1254 - accuracy: 0.3285\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.4706\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.0734 - accuracy: 0.3358\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2423 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.9200 - accuracy: 0.3212\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9927 - accuracy: 0.3529\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.9142 - accuracy: 0.3504\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9645 - accuracy: 0.2353\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.9786 - accuracy: 0.3162\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9428 - accuracy: 0.3714\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.4211 - accuracy: 0.3285\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6035 - accuracy: 0.4706\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.9533 - accuracy: 0.3285\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8375 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7263 - accuracy: 0.4307\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7397 - accuracy: 0.3529\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 1.2302 - accuracy: 0.3504\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.2929 - accuracy: 0.2353\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.8148 - accuracy: 0.3162\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8080 - accuracy: 0.3714\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7052 - accuracy: 0.3431\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6656 - accuracy: 0.4706\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.5949 - accuracy: 0.3504\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5873 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.4523 - accuracy: 0.3796\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2663 - accuracy: 0.2647\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6094 - accuracy: 0.3650\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5458 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 4ms/step - loss: 0.7133 - accuracy: 0.3529\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6836 - accuracy: 0.2286\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6876 - accuracy: 0.3431\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6677 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6332 - accuracy: 0.3285\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6123 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.5671 - accuracy: 0.3796\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.2647\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.9102 - accuracy: 0.3504\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9573 - accuracy: 0.2353\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6374 - accuracy: 0.3750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6131 - accuracy: 0.2857\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7301 - accuracy: 0.2993\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.4118\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7727 - accuracy: 0.3285\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7325 - accuracy: 0.3529\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7373 - accuracy: 0.3285\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7151 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6028 - accuracy: 0.3650\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 1.4894 - accuracy: 0.3162\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.5638 - accuracy: 0.3714\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 1.1106 - accuracy: 0.3212\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9182 - accuracy: 0.3529\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7832 - accuracy: 0.3650\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6035 - accuracy: 0.3529\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 1.6439 - accuracy: 0.3212\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.9966 - accuracy: 0.3529\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 1.0729 - accuracy: 0.3504\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1284 - accuracy: 0.2353\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7538 - accuracy: 0.3162\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.4286\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.2212 - accuracy: 0.3285\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4507 - accuracy: 0.4706\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 0.3338 - accuracy: 0.3358\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4442 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7288 - accuracy: 0.3431\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.8163 - accuracy: 0.2353\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.3784 - accuracy: 0.3650\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2325 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6178 - accuracy: 0.3750\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.2857\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.8089 - accuracy: 0.3431\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7196 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.5755 - accuracy: 0.3358\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6070 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6472 - accuracy: 0.3650\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5960 - accuracy: 0.2647\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 1.1200 - accuracy: 0.3504\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2649 - accuracy: 0.2353\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.8713 - accuracy: 0.3162\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8606 - accuracy: 0.3714\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6602 - accuracy: 0.3285\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6563 - accuracy: 0.4706\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.4610 - accuracy: 0.3358\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 4ms/step - loss: 0.5952 - accuracy: 0.3796\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4778 - accuracy: 0.2647\n",
            "14/14 [==============================] - 1s 5ms/step - loss: 0.7357 - accuracy: 0.3504\n",
            "4/4 [==============================] - 1s 4ms/step - loss: 0.7481 - accuracy: 0.2353\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6837 - accuracy: 0.3971\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.2857\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7828 - accuracy: 0.3212\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7291 - accuracy: 0.3529\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.5036 - accuracy: 0.3358\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5369 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7094 - accuracy: 0.3504\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6686 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6725 - accuracy: 0.3431\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6327 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 0.9435 - accuracy: 0.3162\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0057 - accuracy: 0.3714\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6706 - accuracy: 0.3139\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.4706\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 0.2578 - accuracy: 0.3358\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3477 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.3146 - accuracy: 0.3796\n",
            "4/4 [==============================] - 0s 5ms/step - loss: -0.0097 - accuracy: 0.2647\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 0.3798 - accuracy: 0.3650\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1907 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 0.9139 - accuracy: 0.3676\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0233 - accuracy: 0.2857\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.4336 - accuracy: 0.3285\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.4706\n",
            "14/14 [==============================] - 1s 3ms/step - loss: -0.0480 - accuracy: 0.3358\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1640 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6059 - accuracy: 0.2993\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5547 - accuracy: 0.3529\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.2962 - accuracy: 0.3650\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1370 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.5522 - accuracy: 0.3750\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.2857\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.8048 - accuracy: 0.3212\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7506 - accuracy: 0.3529\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.4821 - accuracy: 0.3358\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7266 - accuracy: 0.3285\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6857 - accuracy: 0.3529\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.5994 - accuracy: 0.3431\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5752 - accuracy: 0.3235\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6381 - accuracy: 0.4485\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5958 - accuracy: 0.2857\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.4813 - accuracy: 0.3285\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.4706\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6214 - accuracy: 0.3431\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6196 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.8638 - accuracy: 0.3212\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9352 - accuracy: 0.3529\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6807 - accuracy: 0.3212\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6377 - accuracy: 0.2059\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.7467 - accuracy: 0.3162\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7113 - accuracy: 0.3714\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6469 - accuracy: 0.3285\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6309 - accuracy: 0.4706\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.5716 - accuracy: 0.3358\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.4412\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6500 - accuracy: 0.3796\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6004 - accuracy: 0.2647\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.5543 - accuracy: 0.3650\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4634 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 1.1612 - accuracy: 0.3162\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1684 - accuracy: 0.3714\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.9821 - accuracy: 0.3212\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8511 - accuracy: 0.3529\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 1.5220 - accuracy: 0.3285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f8874938820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3291 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.5404 - accuracy: 0.3650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f8880d9caf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4859 - accuracy: 0.2647\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.9570 - accuracy: 0.3504\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.0139 - accuracy: 0.2353\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7193 - accuracy: 0.3162\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6838 - accuracy: 0.3714\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.9729 - accuracy: 0.3212\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8343 - accuracy: 0.3529\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 1.2232 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1450 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.9381 - accuracy: 0.3212\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.0385 - accuracy: 0.3529\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.2590 - accuracy: 0.3650\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0706 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 5ms/step - loss: 0.6788 - accuracy: 0.3676\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6616 - accuracy: 0.2857\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.6377 - accuracy: 0.3358\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6576 - accuracy: 0.4706\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.4091 - accuracy: 0.3358\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4770 - accuracy: 0.4412\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.6808 - accuracy: 0.3723\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7105 - accuracy: 0.2647\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.7725 - accuracy: 0.3504\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7958 - accuracy: 0.2353\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.6271 - accuracy: 0.3750\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6173 - accuracy: 0.2857\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.5503 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6048 - accuracy: 0.4706\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.6669 - accuracy: 0.3358\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6495 - accuracy: 0.4412\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.5936 - accuracy: 0.3796\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5025 - accuracy: 0.2647\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.5108 - accuracy: 0.3650\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.7654 - accuracy: 0.3162\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7365 - accuracy: 0.3714\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7530 - accuracy: 0.3212\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7215 - accuracy: 0.3529\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.6818 - accuracy: 0.3504\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6772 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.6290 - accuracy: 0.3796\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5839 - accuracy: 0.2647\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7003 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6794 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 1.0202 - accuracy: 0.3162\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0334 - accuracy: 0.3714\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.6339 - accuracy: 0.3212\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6559 - accuracy: 0.4706\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.2046 - accuracy: 0.3358\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3257 - accuracy: 0.4412\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.8021 - accuracy: 0.3504\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8206 - accuracy: 0.3824\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7246 - accuracy: 0.3796\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7127 - accuracy: 0.3529\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7192 - accuracy: 0.3015\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7051 - accuracy: 0.3714\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.3744 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5168 - accuracy: 0.4412\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.3750 - accuracy: 0.3358\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4312 - accuracy: 0.4412\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.6068 - accuracy: 0.3723\n",
            "2/2 [==============================] - 1s 4ms/step - loss: 0.5574 - accuracy: 0.2647\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.4767 - accuracy: 0.3650\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3901 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.5118 - accuracy: 0.3750\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4795 - accuracy: 0.2857\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.3241 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4931 - accuracy: 0.4706\n",
            "7/7 [==============================] - 1s 7ms/step - loss: 0.7075 - accuracy: 0.3358\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6866 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7627 - accuracy: 0.3212\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7499 - accuracy: 0.3824\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7616 - accuracy: 0.3723\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7669 - accuracy: 0.1471\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7099 - accuracy: 0.3603\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6948 - accuracy: 0.2857\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.6687 - accuracy: 0.2774\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6601 - accuracy: 0.4706\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.4773 - accuracy: 0.3358\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5251 - accuracy: 0.4412\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.7626 - accuracy: 0.3212\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6986 - accuracy: 0.3529\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.6108 - accuracy: 0.3650\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5783 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.8309 - accuracy: 0.3162\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8201 - accuracy: 0.3714\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.8150 - accuracy: 0.3212\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7465 - accuracy: 0.3529\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.6925 - accuracy: 0.2482\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6709 - accuracy: 0.4412\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.6417 - accuracy: 0.3650\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.2647\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7575 - accuracy: 0.3504\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7606 - accuracy: 0.2353\n",
            "7/7 [==============================] - 1s 2ms/step - loss: 0.9486 - accuracy: 0.3456\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9747 - accuracy: 0.4000\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.3352 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5223 - accuracy: 0.4706\n",
            "7/7 [==============================] - 1s 3ms/step - loss: -0.1881 - accuracy: 0.3358\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0494 - accuracy: 0.4412\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.2900 - accuracy: 0.3796\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 0.2647\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7505 - accuracy: 0.4234\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7905 - accuracy: 0.3529\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.5884 - accuracy: 0.3750\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5716 - accuracy: 0.2857\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.5332 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5856 - accuracy: 0.4706\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.2359 - accuracy: 0.3358\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3578 - accuracy: 0.4412\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 1.0657 - accuracy: 0.3212\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.2164 - accuracy: 0.3529\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.5646 - accuracy: 0.3577\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5255 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.3714 - accuracy: 0.3750\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3636 - accuracy: 0.2857\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.8353 - accuracy: 0.3212\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7535 - accuracy: 0.3529\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.7957 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7629 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.7108 - accuracy: 0.3796\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7239 - accuracy: 0.3529\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.4308 - accuracy: 0.3650\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3551 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.7278 - accuracy: 0.3456\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7142 - accuracy: 0.1714\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.5170 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6045 - accuracy: 0.4706\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.6291 - accuracy: 0.3358\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6396 - accuracy: 0.4412\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.5496 - accuracy: 0.3796\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4465 - accuracy: 0.2647\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.6497 - accuracy: 0.4307\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6092 - accuracy: 0.2647\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7561 - accuracy: 0.3235\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7510 - accuracy: 0.3714\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.5286 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6096 - accuracy: 0.4706\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.7103 - accuracy: 0.2701\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6868 - accuracy: 0.3824\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7065 - accuracy: 0.3358\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6736 - accuracy: 0.2353\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.6023 - accuracy: 0.3650\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5477 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.9689 - accuracy: 0.3162\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9564 - accuracy: 0.3714\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.0979 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3559 - accuracy: 0.4706\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.4749 - accuracy: 0.3066\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.4118\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7215 - accuracy: 0.2774\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.2353\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.3936 - accuracy: 0.3650\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.2426 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7828 - accuracy: 0.3456\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7679 - accuracy: 0.3714\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.2670 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5045 - accuracy: 0.4706\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.6121 - accuracy: 0.3650\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6623 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.8821 - accuracy: 0.2555\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.0906 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.4882 - accuracy: 0.3650\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.5914 - accuracy: 0.3750\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5791 - accuracy: 0.2857\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.6629 - accuracy: 0.2993\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6612 - accuracy: 0.4118\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7033 - accuracy: 0.3212\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6762 - accuracy: 0.4412\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.6409 - accuracy: 0.3796\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5719 - accuracy: 0.2647\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.5112 - accuracy: 0.3650\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.6651 - accuracy: 0.3897\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6125 - accuracy: 0.2857\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.7889 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7354 - accuracy: 0.3824\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.6941 - accuracy: 0.3358\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6792 - accuracy: 0.4706\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7477 - accuracy: 0.3066\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7240 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.6770 - accuracy: 0.2920\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6666 - accuracy: 0.2353\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.5282 - accuracy: 0.3750\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5034 - accuracy: 0.2857\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7098 - accuracy: 0.3358\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6946 - accuracy: 0.4118\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7961 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7550 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.8364 - accuracy: 0.3212\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8900 - accuracy: 0.3529\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.7806 - accuracy: 0.3504\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7761 - accuracy: 0.2353\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.6366 - accuracy: 0.3750\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5855 - accuracy: 0.2857\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.2691 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4680 - accuracy: 0.4706\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.9720 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9075 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.3212 - accuracy: 0.3796\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1210 - accuracy: 0.2647\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 1.2313 - accuracy: 0.3504\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.3813 - accuracy: 0.2353\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.6237 - accuracy: 0.3750\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5752 - accuracy: 0.2857\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.4001 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.4706\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.6383 - accuracy: 0.3212\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6247 - accuracy: 0.4412\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.9480 - accuracy: 0.3212\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0228 - accuracy: 0.3529\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.1886 - accuracy: 0.3650\n",
            "2/2 [==============================] - 0s 5ms/step - loss: -0.0312 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.5114 - accuracy: 0.3750\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4952 - accuracy: 0.2857\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.8430 - accuracy: 0.3212\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7934 - accuracy: 0.3529\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7076 - accuracy: 0.2555\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.8520 - accuracy: 0.3212\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9412 - accuracy: 0.3529\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.2750 - accuracy: 0.3650\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1263 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.5551 - accuracy: 0.3750\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5291 - accuracy: 0.2857\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.5195 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.4706\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.6284 - accuracy: 0.3358\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6178 - accuracy: 0.4412\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.6670 - accuracy: 0.3066\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5947 - accuracy: 0.2941\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.6410 - accuracy: 0.3650\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6043 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.8286 - accuracy: 0.3162\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8163 - accuracy: 0.3714\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.8338 - accuracy: 0.3212\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7405 - accuracy: 0.3529\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.2920\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6838 - accuracy: 0.4118\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7370 - accuracy: 0.3358\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7218 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.6240 - accuracy: 0.3650\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5922 - accuracy: 0.1471\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.4632 - accuracy: 0.3750\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4766 - accuracy: 0.2857\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.0514 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4020 - accuracy: 0.4706\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7476 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7202 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.9464 - accuracy: 0.3212\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9418 - accuracy: 0.3529\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 1.4156 - accuracy: 0.3504\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.6066 - accuracy: 0.2353\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 1.0190 - accuracy: 0.3162\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.0148 - accuracy: 0.3714\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7373 - accuracy: 0.2117\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6990 - accuracy: 0.2941\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.8348 - accuracy: 0.3358\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8321 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.4759 - accuracy: 0.3796\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3872 - accuracy: 0.2647\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7820 - accuracy: 0.3577\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8040 - accuracy: 0.2353\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7318 - accuracy: 0.3235\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7075 - accuracy: 0.3714\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.4863 - accuracy: 0.3066\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5789 - accuracy: 0.4706\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.8742 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8168 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7782 - accuracy: 0.3212\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7832 - accuracy: 0.3529\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.5019 - accuracy: 0.3650\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4050 - accuracy: 0.3235\n",
            "7/7 [==============================] - 1s 5ms/step - loss: 0.5254 - accuracy: 0.3750\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4985 - accuracy: 0.2857\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.6297 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6576 - accuracy: 0.4706\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.7249 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6725 - accuracy: 0.3529\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7345 - accuracy: 0.2993\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7517 - accuracy: 0.2941\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.7210 - accuracy: 0.3796\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7189 - accuracy: 0.2353\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.5618 - accuracy: 0.3750\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5237 - accuracy: 0.2857\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.5382 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6085 - accuracy: 0.4706\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.5725 - accuracy: 0.3285\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5898 - accuracy: 0.4118\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.7225 - accuracy: 0.3504\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7079 - accuracy: 0.2647\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 0.5879 - accuracy: 0.3650\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5203 - accuracy: 0.3235\n",
            "18/18 [==============================] - 1s 3ms/step - loss: 0.5763 - accuracy: 0.3567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_parameters = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "print(\"Best parameters :\", best_parameters, \"Best accuracy : \", best_score)"
      ],
      "metadata": {
        "id": "EtPWZlPidCcR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "370bd462-a871-41a8-9826-a9f999fa6d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters : {'batch_size': 10, 'nb_epoch': 10, 'unit': 10} Best accuracy :  0.4210084080696106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = grid_search.predict(X_test)\n",
        "y_pred = y_pred > 0.5"
      ],
      "metadata": {
        "id": "D31m_VsyeGO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3795d9ac-81ac-4527-cb0c-050213847826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "confusion_matrix(y_test,y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFnLhCfCmzvI",
        "outputId": "3ccfb9af-17a8-4b0b-9562-d7deb47f65d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14,  0,  0,  0,  0,  0],\n",
              "       [15,  0,  0,  0,  0,  0],\n",
              "       [ 3,  0,  0,  0,  0,  0],\n",
              "       [ 3,  0,  0,  0,  0,  0],\n",
              "       [ 2,  0,  0,  0,  0,  0],\n",
              "       [ 6,  0,  0,  0,  0,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjS0Iceum2zJ",
        "outputId": "3d980db5-85a7-4238-d00b-1aa32010c5bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.33      1.00      0.49        14\n",
            "           2       0.00      0.00      0.00        15\n",
            "           3       0.00      0.00      0.00         3\n",
            "           5       0.00      0.00      0.00         3\n",
            "           6       0.00      0.00      0.00         2\n",
            "           7       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.33        43\n",
            "   macro avg       0.05      0.17      0.08        43\n",
            "weighted avg       0.11      0.33      0.16        43\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}